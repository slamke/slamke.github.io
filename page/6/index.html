
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>雁渡寒潭 风吹疏竹</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Sun Ke">
    

    
    <meta name="description" content="人生不止眼前的苟且">
<meta property="og:type" content="website">
<meta property="og:title" content="雁渡寒潭 风吹疏竹">
<meta property="og:url" content="slamke.github.io/page/6/index.html">
<meta property="og:site_name" content="雁渡寒潭 风吹疏竹">
<meta property="og:description" content="人生不止眼前的苟且">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雁渡寒潭 风吹疏竹">
<meta name="twitter:description" content="人生不止眼前的苟且">

    
    <link rel="alternative" href="/atom.xml" title="雁渡寒潭 风吹疏竹" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="雁渡寒潭 风吹疏竹" title="雁渡寒潭 风吹疏竹"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="雁渡寒潭 风吹疏竹">雁渡寒潭 风吹疏竹</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:slamke.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/24/Spark-Job任务提交-取消/" title="Spark Job任务提交,取消,查看进度" itemprop="url">Spark Job任务提交,取消,查看进度</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-24T03:29:45.000Z" itemprop="datePublished"> Published 2016-08-24</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>使用一个SparkContext时，可以针对不同Job进行分组提交和取消：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 提交任务</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">SparkContext</span> sc;</span><br><span class="line"><span class="keyword">private</span> <span class="type">SQLContext</span> sqlc;</span><br><span class="line">sc.setJobGroup(jobGroup, description, <span class="literal">true</span>);</span><br><span class="line">sqlc.sql(st);</span><br><span class="line">sc.clearJobGroup();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 取消任务</span></span><br><span class="line">sc.cancelJobGroup(jobGroup）</span><br></pre></td></tr></table></figure>
<p>获取任务执行进度信息：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> jobGroup = getJobGroup(context);</span><br><span class="line"><span class="type">SQLContext</span> sqlc = getSparkInterpreter().getSQLContext();</span><br><span class="line"><span class="type">SparkContext</span> sc = sqlc.sparkContext();</span><br><span class="line">int completedTasks = <span class="number">0</span>;</span><br><span class="line">int totalTasks = <span class="number">0</span>;</span><br><span class="line"><span class="type">JobProgressListener</span> sparkListener = <span class="keyword">new</span> <span class="type">JobProgressListener</span>(context.getConf());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">DAGScheduler</span> scheduler = sc.dagScheduler();</span><br><span class="line"><span class="type">HashSet</span>&lt;<span class="type">ActiveJob</span>&gt; jobs = scheduler.activeJobs();</span><br><span class="line"><span class="type">Iterator</span>&lt;<span class="type">ActiveJob</span>&gt; it = jobs.iterator();</span><br><span class="line"><span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">      <span class="type">ActiveJob</span> job = it.next();</span><br><span class="line">      <span class="type">String</span> g = (<span class="type">String</span>) job.properties().get(<span class="string">"spark.jobGroup.id"</span>);</span><br><span class="line">      <span class="keyword">if</span> (jobGroup.equals(g)) &#123;</span><br><span class="line">      int[] progressInfo = <span class="literal">null</span>;</span><br><span class="line">        </span><br><span class="line">      progressInfo = getProgressFromStage_1_1x(sparkListener, job.finalStage());</span><br><span class="line">        </span><br><span class="line">      totalTasks += progressInfo[<span class="number">0</span>];</span><br><span class="line">      completedTasks += progressInfo[<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (totalTasks == <span class="number">0</span>) &#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> completedTasks * <span class="number">100</span> / totalTasks;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> int[] getProgressFromStage_1_1x(<span class="type">JobProgressListener</span> sparkListener, <span class="type">Stage</span> stage) &#123;</span><br><span class="line">    int numTasks = stage.numTasks();</span><br><span class="line">    int completedTasks = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">Method</span> stageIdToData = sparkListener.getClass().getMethod(<span class="string">"stageIdToData"</span>);</span><br><span class="line">      <span class="type">HashMap</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Object</span>, <span class="type">Object</span>&gt;, <span class="type">Object</span>&gt; stageIdData =</span><br><span class="line">          (<span class="type">HashMap</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Object</span>, <span class="type">Object</span>&gt;, <span class="type">Object</span>&gt;) stageIdToData.invoke(sparkListener);</span><br><span class="line">      <span class="type">Class</span>&lt;?&gt; stageUIDataClass =</span><br><span class="line">          <span class="keyword">this</span>.getClass().forName(<span class="string">"org.apache.spark.ui.jobs.UIData$StageUIData"</span>);</span><br><span class="line"></span><br><span class="line">      <span class="type">Method</span> numCompletedTasks = stageUIDataClass.getMethod(<span class="string">"numCompleteTasks"</span>);</span><br><span class="line"></span><br><span class="line">      <span class="type">Set</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Object</span>, <span class="type">Object</span>&gt;&gt; keys =</span><br><span class="line">          <span class="type">JavaConverters</span>.asJavaSetConverter(stageIdData.keySet()).asJava();</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">Tuple2</span>&lt;<span class="type">Object</span>, <span class="type">Object</span>&gt; k : keys) &#123;</span><br><span class="line">        <span class="keyword">if</span> (stage.id() == (int) k._1()) &#123;</span><br><span class="line">          <span class="type">Object</span> uiData = stageIdData.get(k).get();</span><br><span class="line">          completedTasks += (int) numCompletedTasks.invoke(uiData);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> e) &#123;</span><br><span class="line">      logger.error(<span class="string">"Error on getting progress information"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">List</span>&lt;<span class="type">Stage</span>&gt; parents = <span class="type">JavaConversions</span>.asJavaList(stage.parents());</span><br><span class="line">    <span class="keyword">if</span> (parents != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">Stage</span> s : parents) &#123;</span><br><span class="line">        int[] p = getProgressFromStage_1_1x(sparkListener, s);</span><br><span class="line">        numTasks += p[<span class="number">0</span>];</span><br><span class="line">        completedTasks += p[<span class="number">1</span>];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> int[] &#123;numTasks, completedTasks&#125;;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Spark/">Spark</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Spark/">Spark</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/23/Hive-on-Spark-如何进行小文件merge/" title="Hive on Spark 如何进行小文件merge" itemprop="url">Hive on Spark 如何进行小文件merge</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-23T01:32:07.000Z" itemprop="datePublished"> Published 2016-08-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hive中有相关的属性property可以进行设置，对执行结果进行小文件merge；当使用Spark作为Hive的执行引擎时，遇到小文件合并需求时，也可以进行处理：</p>
<ol>
<li><p>配置属性 hive.merge.sparkfiles=true<br><a href="https://issues.apache.org/jira/browse/HIVE-8043" target="_blank" rel="external">https://issues.apache.org/jira/browse/HIVE-8043</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started</a><br>ps： 奈何公司的Spark版本不支持，命令行设置&amp;hive-site.xml设置均无效</p>
</li>
<li><p>使用distribute by命令进行数据重分布<br>使用时间戳取模进行数据分布<br><a href="http://stackoverflow.com/questions/31009834/merge-multiple-small-files-in-to-few-larger-files-in-spark" target="_blank" rel="external">http://stackoverflow.com/questions/31009834/merge-multiple-small-files-in-to-few-larger-files-in-spark</a><br>Demo:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> table1 <span class="keyword">where</span> yymmdd=<span class="string">'20160816'</span> <span class="keyword">distribute</span> <span class="keyword">by</span> (<span class="keyword">column</span> % <span class="number">64</span>)</span><br></pre></td></tr></table></figure></li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Hive/">Hive</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Hive/">Hive</a><a href="/tags/Spark/">Spark</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/23/Hive中order-by-sort-by-distribute-by-cluster-by的区别/" title="Hive中order by,sort by,distribute by,cluster by的区别" itemprop="url">Hive中order by,sort by,distribute by,cluster by的区别</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-23T01:25:20.000Z" itemprop="datePublished"> Published 2016-08-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>转自：<a href="http://blog.csdn.net/lzm1340458776/article/details/43306115" target="_blank" rel="external">http://blog.csdn.net/lzm1340458776/article/details/43306115</a></p>
<h2 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h2><p>order by会对输入做<strong>全局排序</strong>，因此<strong>只有一个Reducer</strong>(多个Reducer无法保证全局有序)，然而只有一个Reducer，会导致当输入规模较大时，消耗较长的计算时间。关于order by的详细介绍请参考这篇文章：Hive Order by操作。</p>
<h2 id="sort-by"><a href="#sort-by" class="headerlink" title="sort by"></a>sort by</h2><p>sort by不是全局排序，其在数据进入reducer前完成排序，因此，如果用sort by进行排序，并且<strong>设置mapred.reduce.tasks&gt;1，则sort by只会保证每个reducer的输出有序</strong>，并不保证全局有序。sort by不同于order by，它不受hive.mapred.mode属性的影响，sort by的数据只能保证在同一个reduce中的数据可以按指定字段排序。使用sort by你可以指定执行的reduce个数(通过set mapred.reduce.tasks=n来指定)，对输出的数据再执行归并排序，即可得到全部结果。</p>
<h2 id="distribute-by"><a href="#distribute-by" class="headerlink" title="distribute by"></a>distribute by</h2><p><strong>distribute by是控制在map端如何拆分数据给reduce端的</strong>。hive会根据distribute by后面列，对应reduce的个数进行分发，默认是采用hash算法。sort by为每个reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此，distribute by经常和sort by配合使用。</p>
<p>注：Distribute by和sort by的使用场景</p>
<ol>
<li><p>Map输出的文件大小不均。</p>
</li>
<li><p>Reduce输出文件大小不均。</p>
</li>
<li><p>小文件过多。</p>
</li>
<li><p>文件超大。</p>
</li>
</ol>
<h2 id="cluster-by"><a href="#cluster-by" class="headerlink" title="cluster by"></a>cluster by</h2><p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是倒叙排序，不能指定排序规则为ASC或者DESC。</p>
<p>Demo：<br>根据年份和气温对气象数据进行排序，以确保所具有相同年份的行最终都在一个reduce分区中。<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; select * from temperature distribute by year sort by year asc,tempra desc;  </span><br><span class="line">//MapReduce...  </span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2  </span><br><span class="line">//MapReduce...  </span><br><span class="line">OK  </span><br><span class="line">year    tempra  </span><br><span class="line">2008    35`C  </span><br><span class="line">2008    32.5`C  </span><br><span class="line">2008    31`C  </span><br><span class="line">2008    31.5`C  </span><br><span class="line">2008    30`C  </span><br><span class="line">2015    41`C  </span><br><span class="line">2015    39`C  </span><br><span class="line">2015    37`C  </span><br><span class="line">2015    36`C  </span><br><span class="line">2015    35`C  </span><br><span class="line">2015    33`C  </span><br><span class="line">Time taken: 17.358 seconds</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Hive/">Hive</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Hive/">Hive</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/11/Dropwizard--非常棒的Java-REST服务器栈/" title="Dropwizard--非常棒的Java REST服务器栈" itemprop="url">Dropwizard--非常棒的Java REST服务器栈</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-11T03:57:38.000Z" itemprop="datePublished"> Published 2016-08-11</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="什么是Dropwizard？"><a href="#什么是Dropwizard？" class="headerlink" title="什么是Dropwizard？"></a>什么是Dropwizard？</h2><p>Dropwizard 是一个开源的Java框架，用于开发OPS友好、高性能的基于REST的后端。它是由Yammer开发的，来驱动基于JVM的后端。</p>
<p>Dropwizard提供同类最佳的Java库到一个嵌入式应用程序包。它由以下部分组成：</p>
<ol>
<li>嵌入式Jetty：每一个应用程序被打包成一个jar（而不是war）文件，并开始自己的嵌入式Jetty容器。没有任何war文件和外部servlet容器。</li>
<li>JAX-RS：Jersey（JAX-RS的参考实现）是用来写基于REST的Web服务的。</li>
<li>JSON：REST服务用的是JSON，Jackson库用来做所有的JSON处理。</li>
<li>日志：使用Logback和SLF4J完成。</li>
<li>Hibernate验证：Dropwizard使用Hibernate验证API进行声明性验证。</li>
<li>指标：Dropwizard支持监控使用标准库，它在监控代码方面有无与伦比的洞察力。</li>
</ol>
<p>除了上面提到的这几个，Dropwizard还使用了一些其他的库，你可以在这里找到<a href="http://dropwizard.codahale.com/getting-started/" target="_blank" rel="external">完整的列表</a>。</p>
<h2 id="为什么是Dropwizard？"><a href="#为什么是Dropwizard？" class="headerlink" title="为什么是Dropwizard？"></a>为什么是Dropwizard？</h2><p>我决定学Dropwizard的原因有以下几点：</p>
<ol>
<li>快速的项目引导：如果你已经在使用Spring和Java EE，你就会明白开发人员在引导项目时的痛苦。使用Dropwizard，你只需要在你的 pom.xml 文件中添加一个依赖就完成了。</li>
<li>应用指标：Dropwizard自带应用程序指标的支持。它提供了类似请求/响应时间这种非常有用的信息，只要把@ 定时注解来获取方法的执行时间。</li>
<li>生产力：每个Dropwizard应用程序有一个启动Jetty容器的主程序。这意味着，完全可以把应用程序作为一个主程序在IDE中运行和调试。所以就没有重新编译或部署war文件。</li>
</ol>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p><a href="https://segmentfault.com/a/1190000000359827" target="_blank" rel="external">Dropwizard —— 非常棒的Java REST服务器栈</a></p>
<p><a href="https://github.com/shekhargulati/day13-dropwizard-mongodb-demo-app" target="_blank" rel="external">day13-dropwizard-mongodb-demo-app</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/REST/">REST</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/REST/">REST</a><a href="/tags/Dropwizard/">Dropwizard</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/10/scala-mutable和immutable类型转换/" title="scala mutable和immutable类型转换" itemprop="url">scala mutable和immutable类型转换</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-10T01:46:12.000Z" itemprop="datePublished"> Published 2016-08-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>一般而言，from mutable to immutable, 使用 to<em> 系列方法in mutable collections, like MutableList and ListBuffer’s toList method.<br>from immutable to mutable, 使用构造函数: scala.collection.mutable.ListBuffer(immtableList: _</em>).</p>
<blockquote>
<p>Note that the to* methods like toList, toMap are is performed in constant time.</p>
</blockquote>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// from mutable to immutable</span></span><br><span class="line"><span class="keyword">val</span> mutableMap1 = immutableMap.toMap() <span class="comment">// after 2.8</span></span><br><span class="line"><span class="keyword">val</span> mutbaleMap2 = collection.immutable.<span class="type">Map</span>(x.toList: _*) <span class="comment">// before 2.8</span></span><br><span class="line"><span class="comment">// from immutable to mutable</span></span><br><span class="line"><span class="keyword">val</span> immutableMap = scala.collection.immutable.<span class="type">Map</span>(<span class="number">1</span> -&gt; <span class="string">"1"</span>, <span class="number">2</span> -&gt; <span class="string">"2"</span>)</span><br><span class="line"><span class="keyword">val</span> mutableMap = scala.collection.mutable.<span class="type">Map</span>(immutableMap: _*)</span><br></pre></td></tr></table></figure>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// from mutable to immutable</span></span><br><span class="line"><span class="keyword">val</span> immutableList = mutableListBuffer.toList</span><br><span class="line"><span class="comment">// from immutable to mutable</span></span><br><span class="line"><span class="keyword">val</span> immutableList = scala.collection.immutable.<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> mutableListBuffer = scala.collection.mutable.<span class="type">ListBuffer</span>(immutableList: _*)</span><br></pre></td></tr></table></figure>
<p><a href="http://qiita.com/visualskyrim/items/1e92fc99fc3eaf004778" target="_blank" rel="external">参考链接</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Scala/">Scala</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Scala/">Scala</a><a href="/tags/类型转换/">类型转换</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/08/04/Spark性能优化/" title="Spark性能优化" itemprop="url">Spark性能优化</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-08-04T04:33:05.000Z" itemprop="datePublished"> Published 2016-08-04</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>参考:<br><a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/" target="_blank" rel="external">how-to-tune-your-apache-spark-jobs-part-1</a><br><a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/" target="_blank" rel="external">how-to-tune-your-apache-spark-jobs-part-2</a><br><a href="http://gitlab.baidu.com/metastore/metastore_doc/blob/master/file/tuning_spark_streaming.md" target="_blank" rel="external">tuning_spark_streaming</a><br><a href="http://www.iteblog.com/archives/1333" target="_blank" rel="external">Spark Streaming性能调优详解</a></p>
<p><a href="http://www.iteblog.com/archives/1672" target="_blank" rel="external">Spark性能优化：shuffle调优</a><br><a href="http://www.iteblog.com/archives/1671" target="_blank" rel="external">Spark性能优化：数据倾斜调优</a></p>
<p><a href="http://www.iteblog.com/archives/1657" target="_blank" rel="external">Spark性能优化：开发调优篇</a><br><a href="https://spark-summit.org/east-2016/events/top-5-mistakes-when-writing-spark-applications/" target="_blank" rel="external">top-5-mistakes-when-writing-spark-applications</a>  强力推荐</p>
<h2 id="一-基础说明"><a href="#一-基础说明" class="headerlink" title="一 基础说明"></a>一 基础说明</h2><ul>
<li>job–&gt;stage–&gt;task<br>job划分为stage，stage划分为Task，一个Task运行在一个core上</li>
<li>executor–&gt;core<br>The number of tasks in a stage is the same as the number of partitions in the last RDD in the stage. </li>
</ul>
<h2 id="二-Tuning-Resource-Allocation"><a href="#二-Tuning-Resource-Allocation" class="headerlink" title="二 Tuning Resource Allocation"></a>二 Tuning Resource Allocation</h2><p><a href="http://www.infoq.com/cn/presentations/gc-tuning-of-spark-application" target="_blank" rel="external">Spark应用的GC调优</a> –&gt;重点讲解了G1垃圾回收器的调优工作<br><a href="http://www.iteblog.com/archives/1659" target="_blank" rel="external">Spark性能优化：资源调优篇</a><br>Every Spark executor in an application has the same fixed number of cores and same fixed heap size.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--executor-cores/ spark.executor.cores 提交时通过该参数设置每个executor的core数量，决定了<span class="type">Task</span>的并行度</span><br><span class="line">--executor-memory/spark.executor.memory 设置executor的<span class="type">JVM</span> memory</span><br><span class="line">--num-executors/spark.executor.instances 设置executor的数量</span><br><span class="line">spark.dynamicAllocation.enabled 设置动态申请资源(value设为<span class="literal">true</span>)，此时不要设置num-executors</span><br><span class="line">spark.yarn.executor.memoryOverhead 设置堆外的memory大小</span><br></pre></td></tr></table></figure>
<h3 id="spark-dynamicAllocation-enabled"><a href="#spark-dynamicAllocation-enabled" class="headerlink" title="spark.dynamicAllocation.enabled"></a>spark.dynamicAllocation.enabled</h3><p>executor空闲超时后，会被移除<br>对于Spark Streaming，数据按时间段到达，为了防止executor频繁出现添加移除现象，应该禁用该功能。</p>
<h3 id="内存格局"><a href="#内存格局" class="headerlink" title="内存格局"></a>内存格局</h3><p><img src="http://blog.cloudera.com/wp-content/uploads/2015/03/spark-tuning2-f1.png" alt="enter image description here"></p>
<p>说明:</p>
<ul>
<li><p>The application master, which is a non-executor container with the special capability of requesting containers from YARN, takes up resources of its own that must be budgeted in. In yarn-client mode, it defaults to a 1024MB and one vcore. In yarn-cluster mode, the application master runs the driver, so it’s often useful to bolster its resources with the –driver-memory and –driver-cores properties.</p>
</li>
<li><p>Running executors with too much memory often results in excessive garbage collection delays. 64GB is a rough guess at a good upper limit for a single executor.最多4G内存，防止GC压力过大。</p>
</li>
<li><p>I’ve noticed that the HDFS client has trouble with tons of concurrent threads. A rough guess is that at most five tasks per executor can achieve full write throughput, so it’s good to keep the number of cores per executor below that number. 最多5个Task可以同时达到最高的HDFS写入带宽</p>
</li>
<li><p>Running tiny executors (with a single core and just enough memory needed to run a single task, for example) throws away the benefits that come from running multiple tasks in a single JVM. For example, broadcast variables need to be replicated once on each executor, so many small executors will result in many more copies of the data.</p>
</li>
</ul>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项:"></a>注意事项:</h3><p>保留内存和core给hadoop ，yarn等系统运行</p>
<h3 id="Slimming-Down-Your-Data-Structures"><a href="#Slimming-Down-Your-Data-Structures" class="headerlink" title="Slimming Down Your Data Structures"></a>Slimming Down Your Data Structures</h3><p>定制序列化方法,减少序列化后的存储占用<br>spark.serializer=org.apache.spark.serializer.KryoSerializer</p>
<h2 id="三-Tuning-Parallelism"><a href="#三-Tuning-Parallelism" class="headerlink" title="三 Tuning Parallelism"></a>三 Tuning Parallelism</h2><p>分区过少时，Task数量有限，无法充分利用机器资源。<br>方法:</p>
<ul>
<li>Use the repartition transformation, which will trigger a shuffle.</li>
<li>Configure your InputFormat to create more splits.</li>
<li>Write the input data out to HDFS with a smaller block size.</li>
</ul>
<h3 id="3-1-参数spark-default-parallelism"><a href="#3-1-参数spark-default-parallelism" class="headerlink" title="3.1 参数spark.default.parallelism"></a>3.1 参数spark.default.parallelism</h3><p>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</p>
<p>　　参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。</p>
<h2 id="减少shuffle以及shuffle的数据量"><a href="#减少shuffle以及shuffle的数据量" class="headerlink" title="减少shuffle以及shuffle的数据量"></a>减少shuffle以及shuffle的数据量</h2><ul>
<li><p>操作<strong>repartition</strong> , <strong>join</strong>, <strong>cogroup</strong>, and any of the <strong>*By</strong> or <strong>*ByKey</strong> transformations can result in shuffles. </p>
</li>
<li><p>Avoid <strong>groupByKey</strong> when performing an associative reductive operation. For example, <strong>rdd.groupByKey().mapValues(_.sum)</strong> will produce the same results as <strong>rdd.reduceByKey(<em> + </em>)</strong><br>However, the former will transfer the entire dataset across the network, while the latter will compute local sums for each key in each partition and combine those local sums into larger sums after shuffling.<br><img src="http://www.iteblog.com/pic/reduce_by.png" alt="enter image description here"><br><img src="http://www.iteblog.com/pic/group_by.png" alt="enter image description here"><br>以下函数应该优先于 groupByKey ：</p>
</li>
</ul>
<ol>
<li>combineByKey组合数据，但是组合之后的数据类型与输入时值的类型不一样。</li>
<li>foldByKey 合并每一个 key 的所有值，在级联函数和“零值”中使用。</li>
</ol>
<ul>
<li>Avoid <strong>reduceByKey</strong> When the input and output value types are different. <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(kv =&gt; (kv._1, <span class="keyword">new</span> <span class="type">Set</span>[<span class="type">String</span>]() + kv._2))</span><br><span class="line">    .reduceByKey(_ ++ _)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>This code results in tons of unnecessary object creation because a new set must be allocated for each record. It’s better to use aggregateByKey, which performs the map-side aggregation more efficiently:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> zero = <span class="keyword">new</span> collection.mutable.<span class="type">Set</span>[<span class="type">String</span>]()</span><br><span class="line">rdd.aggregateByKey(zero)(</span><br><span class="line">    (set, v) =&gt; set += v,</span><br><span class="line">    (set1, set2) =&gt; set1 ++= set2)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>Avoid the <code>flatMap-join-groupBy</code> pattern. When two datasets are already grouped by key and you want to join them and keep them grouped, you can just use <code>cogroup</code>. That avoids all the overhead associated with unpacking and repacking the groups.     join数据源时直接使用<code>cogroup</code></li>
</ul>
<h2 id="四-shuffle不发生的情况"><a href="#四-shuffle不发生的情况" class="headerlink" title="四 shuffle不发生的情况"></a>四 shuffle不发生的情况</h2><ul>
<li>两个数据源进行join时，已经进行group分组后，如果分组时使用的是同样的partitioner，那么进行join时是不需要进行shuffle的。</li>
<li>当数据量较少时，使用广播变量，不需要shuffle</li>
</ul>
<h2 id="When-More-Shuffles-are-Better"><a href="#When-More-Shuffles-are-Better" class="headerlink" title="When More Shuffles are Better"></a>When More Shuffles are Better</h2><p>当数据partition较少，数据量较大时，进行shuffle可以提高partition数量，提高并行度，从而达到提高效率的目的。</p>
<h2 id="五-RDD"><a href="#五-RDD" class="headerlink" title="五 RDD"></a>五 RDD</h2><p><a href="http://www.iteblog.com/archives/1657" target="_blank" rel="external">Spark性能优化：开发调优篇</a></p>
<ul>
<li>原则一：避免创建重复的RDD</li>
<li>原则二：尽可能复用同一个RDD</li>
<li>原则三：对多次使用的RDD进行持久化  cache persist</li>
<li>原则四：尽量避免使用shuffle类算子  广播大变量 </li>
<li>原则五：使用map-side预聚合的shuffle操作</li>
<li>原则六：使用高性能的算子<ul>
<li><strong>使用reduceByKey/aggregateByKey替代groupByKey</strong></li>
<li><strong>使用mapPartitions替代普通map(mapPartitions类的算子</strong>，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。)</li>
<li><strong>使用foreachPartitions替代foreach</strong>(一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据)</li>
<li><strong>使用filter之后进行coalesce操作</strong>(通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。)</li>
</ul>
</li>
<li>原则七：广播大变量 </li>
<li>原则八：使用Kryo优化序列化性能</li>
<li>原则九：优化数据结构<h2 id="5-1-不要将大型RDD中所有元素发送到Driver端"><a href="#5-1-不要将大型RDD中所有元素发送到Driver端" class="headerlink" title="5.1 不要将大型RDD中所有元素发送到Driver端"></a>5.1 不要将大型RDD中所有元素发送到Driver端</h2>慎重使用<code>collect countByKey countByValue collectAsMap</code>等函数，使用<code>take或者takeSample</code>来限制数据大小的上限</li>
</ul>
<h2 id="六-其他"><a href="#六-其他" class="headerlink" title="六 其他"></a>六 其他</h2><h3 id="6-1-Spark优化：禁止应用程序将依赖的Jar包传到HDFS"><a href="#6-1-Spark优化：禁止应用程序将依赖的Jar包传到HDFS" class="headerlink" title="6.1 Spark优化：禁止应用程序将依赖的Jar包传到HDFS"></a>6.1 Spark优化：禁止应用程序将依赖的Jar包传到HDFS</h3><p><a href="http://www.iteblog.com/archives/1173" target="_blank" rel="external">Spark优化：禁止应用程序将依赖的Jar包传到HDFS</a><br>编辑spark-default.conf文件，添加以下内容：<br>spark.yarn.jar=hdfs://my/home/iteblog/spark_lib/spark-assembly-1.1.0-hadoop2.2.0.jar<br>也就是使得spark.yarn.jar指向我们HDFS上的Spark lib库。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Spark/">Spark</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Spark/">Spark</a><a href="/tags/性能优化/">性能优化</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/07/31/Java动态技术/" title="Java动态技术" itemprop="url">Java动态技术</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-07-31T09:35:10.000Z" itemprop="datePublished"> Published 2016-07-31</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><a href="https://www.ibm.com/developerworks/cn/java/j-dyn0916/" target="_blank" rel="external">Java 编程的动态性， 第四部分: 用 Javassist 进行类转换</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Java/">Java</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Java/">Java</a><a href="/tags/动态/">动态</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/07/26/Servlet-Listener之ServletContextListener用法/" title="Servlet Listener之ServletContextListener用法" itemprop="url">Servlet Listener之ServletContextListener用法</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-07-26T13:28:46.000Z" itemprop="datePublished"> Published 2016-07-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>本文旨在解释JavaEE中的ServletContextListener接口及用法。 </p>
<p>1.何时需要使用ServletContextListener？ </p>
<p>通常我们可能有这样的需求：即在web 应用启动之前运行一些代码。例如：我们可能需要创建一个数据库连接以便web应用在任何时候都能使用它执行一些操作，并且当web应用关闭的时候能够关闭数据库连接。 </p>
<p>2.如何实现这个需求？</p>
<p>Java EE规范提供了一个叫ServletContextListener的接口，这个接口可以实现我们的需求。ServletContextListener监听servlet context的生命周期事件。当这个listener关联的web应用启动和关闭的时候，这个接口会收到通知。下面是javadoc对这个接口的说明：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Implementations of this interface receive notifications about changes to the servlet context of the web application they are part of. To receive notification events, the implementation class must be configured in the deployment descriptor for the web application.</span><br></pre></td></tr></table></figure></p>
<p>如果想要监听web应用的启动，可以使用contextInitialized(ServletContextEvent event)方法。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Notification that the web application initialization process is starting. All ServletContextListeners are notified of context initialization before any filter or servlet in the web application is initialized.</span><br></pre></td></tr></table></figure></p>
<p>如果要监听web应用的停止（关闭），用contextDestroyed(ServletCOntextEvent event)方法。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Notification that the servlet context is about to be shut down. All servlets and filters have been destroy()ed before any ServletContextListeners are notified of context destruction.</span><br></pre></td></tr></table></figure></p>
<p>如下创建一个监听器类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cruise;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletContextEvent;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletContextListener;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServletContextListener</span> <span class="keyword">implements</span> <span class="title">ServletContextListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextInitialized</span><span class="params">(ServletContextEvent event)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"context initialized"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextDestroyed</span><span class="params">(ServletContextEvent event)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"context destroyed"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来在web.xml文件中配置listener<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">web-app</span> <span class="attr">...</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">listener</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">listener-class</span>&gt;</span>com.thejavageek.MyServletContextListener<span class="tag">&lt;/<span class="name">listener-class</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">listener</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>配置完成后，部署应用到tomcat服务器并启动tomcat，将会看到如下的日志。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INFO: Starting service Catalina</span><br><span class="line">Oct 24, 2015 10:52:04 AM org.apache.catalina.core.StandardEngine start</span><br><span class="line">INFO: Starting Servlet Engine: Apache Tomcat/6.0.35</span><br><span class="line">context initialized</span><br><span class="line">Oct 24, 2015 10:52:04 AM org.apache.coyote.http11.Http11Protocol start</span><br><span class="line">INFO: Starting Coyote HTTP/1.1 on http-8080</span><br><span class="line">Oct 24, 2015 10:52:04 AM org.apache.jk.common.ChannelSocket init</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>继承thread<br>``` java<br>public class ThreadListener extends Thread implements ServletContextListener {</p>
<p> public void contextInitialized(ServletContextEvent event) {</p>
<pre><code>super.start();
</code></pre><p> }</p>
<p> public void contextDestroyed(ServletContextEvent event) {</p>
<pre><code>super.stop();
</code></pre><p> }</p>
<p> @override<br> public void run(){</p>
<p> }</p>
</li>
</ol>
<p>}</p>
<p>``` </p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Web/">Web</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Web/">Web</a><a href="/tags/Spring/">Spring</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/07/22/WebHDFS与HttpFS的使用/" title="WebHDFS与HttpFS的使用" itemprop="url">WebHDFS与HttpFS的使用</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-07-22T13:49:24.000Z" itemprop="datePublished"> Published 2016-07-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="WebHDFS与HttpFS的使用"><a href="#WebHDFS与HttpFS的使用" class="headerlink" title="WebHDFS与HttpFS的使用"></a>WebHDFS与HttpFS的使用</h2><h2 id="WebHDFS"><a href="#WebHDFS" class="headerlink" title="WebHDFS"></a>WebHDFS</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>提供HDFS的RESTful接口，可通过此接口进行HDFS文件操作。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>WebHDFS服务内置在HDFS中，不需额外安装、启动。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>需要在hdfs-site.xml打开WebHDFS开关，此开关默认打开。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>连接NameNode的50070端口进行文件操作。</p>
<p>比如：<figure class="highlight plain"><figcaption><span>"http://ctrl:50070/webhdfs/v1/?op=liststatus&user.name=root" | python -mjson.tool```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 更多操作</span><br><span class="line">参考文档：[官方WebHDFS REST API](https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html)</span><br><span class="line"></span><br><span class="line">## HttpFS(Hadoop HDFS over HTTP)</span><br><span class="line"></span><br><span class="line">### 介绍</span><br><span class="line"></span><br><span class="line">HttpFS is a server that provides a REST HTTP gateway supporting all HDFS File System operations (read and write). And it is inteoperable with the webhdfs REST HTTP API.</span><br><span class="line"></span><br><span class="line">### 安装</span><br><span class="line"></span><br><span class="line">Hadoop自带，不需要额外安装。默认服务未启动，需要手工启动。</span><br><span class="line"></span><br><span class="line">### 配置</span><br><span class="line"></span><br><span class="line">- httpfs-site.xml</span><br><span class="line">有配置文件httpfs-site.xml，此配置文件一般保存默认即可，无需修改。</span><br><span class="line"></span><br><span class="line">- hdfs-site.xml</span><br><span class="line">需要增加如下配置，其他两个参数名称中的root代表的是启动hdfs服务的OS用户，应以实际的用户名称代替。</span><br><span class="line">``` xml</span><br><span class="line">&lt;property&gt;  </span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;  </span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;  </span><br><span class="line">&lt;property&gt;  </span><br><span class="line">&lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;  </span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/httpfs.sh start</span><br><span class="line">sbin/httpfs.sh stop</span><br></pre></td></tr></table></figure>
<p>启动后，默认监听14000端口：<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ctrl sbin]<span class="comment"># netstat -antp | grep 14000</span></span><br><span class="line">tcp        <span class="number">0</span>      <span class="number">0</span> :::<span class="number">14000</span>   :::*       LISTEN      <span class="number">7415</span>/java</span><br><span class="line">[root@ctrl sbin]<span class="comment">#</span></span><br></pre></td></tr></table></figure></p>
<h3 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h3><p>curl “<a href="http://ctrl:14000/webhdfs/v1/?op=liststatus&amp;user.name=root" target="_blank" rel="external">http://ctrl:14000/webhdfs/v1/?op=liststatus&amp;user.name=root</a>“ | python -mjson.tool</p>
<h3 id="更多操作"><a href="#更多操作" class="headerlink" title="更多操作"></a>更多操作</h3><h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p>更多操作：<br><a href="https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html" target="_blank" rel="external">官方WebHDFS REST API</a><br><a href="http://hadoop.apache.org/docs/r2.4.1/hadoop-hdfs-httpfs/index.html" target="_blank" rel="external">HttpFS官方文档</a></p>
<h3 id="WebHDFS与HttpFS的关系"><a href="#WebHDFS与HttpFS的关系" class="headerlink" title="WebHDFS与HttpFS的关系"></a>WebHDFS与HttpFS的关系</h3><p>WebHDFS vs HttpFs Major difference between WebHDFS and HttpFs: WebHDFS needs access to all nodes of the cluster and when some data is read it is transmitted from that node directly, whereas in HttpFs, a singe node will act similar to a “gateway” and will be a single point of data transfer to the client node. So, HttpFs could be choked during a large file transfer but the good thing is that we are minimizing the footprint required to access HDFS.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Hadoop/">Hadoop</a><a href="/tags/HDFS/">HDFS</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/06/14/Spring-scheduled注解执行定时任务/" title="Spring @scheduled注解执行定时任务" itemprop="url">Spring @scheduled注解执行定时任务</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Sun Ke" target="_blank" itemprop="author">Sun Ke</a>
		
  <p class="article-time">
    <time datetime="2016-06-14T02:30:29.000Z" itemprop="datePublished"> Published 2016-06-14</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ol>
<li>创建spring-task.xml 文件</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!---加入：xmlns:task="http://www.springframework.org/schema/task"</span><br><span class="line">   xsi:schemaLocation="http://www.springframework.org/schema/task</span><br><span class="line">	http://www.springframework.org/schema/task/spring-task-3.1.xsd"</span><br><span class="line">--&gt;</span></span><br><span class="line"></span><br><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;  </span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span>  </span><br><span class="line">    <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span>   </span><br><span class="line">    <span class="attr">xmlns:tx</span>=<span class="string">"http://www.springframework.org/schema/tx"</span>  </span><br><span class="line">    <span class="attr">xmlns:aop</span>=<span class="string">"http://www.springframework.org/schema/aop"</span>  </span><br><span class="line">    <span class="attr">xmlns:context</span>=<span class="string">"http://www.springframework.org/schema/context"</span>  </span><br><span class="line">    <span class="attr">xmlns:mvc</span>=<span class="string">"http://www.springframework.org/schema/mvc"</span></span><br><span class="line">    <span class="attr">xmlns:task</span>=<span class="string">"http://www.springframework.org/schema/task"</span>  </span><br><span class="line">    <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans     </span><br><span class="line">    http://www.springframework.org/schema/beans/spring-beans-3.2.xsd     </span><br><span class="line">    http://www.springframework.org/schema/tx     </span><br><span class="line">    http://www.springframework.org/schema/tx/spring-tx-3.2.xsd   </span><br><span class="line">    http://www.springframework.org/schema/aop  </span><br><span class="line">    http://www.springframework.org/schema/aop/spring-aop-3.2.xsd   </span><br><span class="line">    http://www.springframework.org/schema/context    </span><br><span class="line">    http://www.springframework.org/schema/context/spring-context-3.2.xsd    </span><br><span class="line">    http://www.springframework.org/schema/mvc  </span><br><span class="line">    http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd</span><br><span class="line">    http://www.springframework.org/schema/task  </span><br><span class="line">    http://www.springframework.org/schema/task/spring-task-3.2.xsd</span><br><span class="line">   "</span>&gt;</span>  </span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">task:annotation-driven</span> /&gt;</span> <span class="comment">&lt;!-- 定时器开关--&gt;</span>  </span><br><span class="line">  </span><br><span class="line">      </span><br><span class="line">    <span class="tag">&lt;<span class="name">context:annotation-config</span>/&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 自动扫描的包名 --&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.spring.task"</span> /&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor"</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>实现接口和实现类，添加注解和说明</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IMyTestService</span> </span>&#123;  </span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">myTest</span><span class="params">()</span></span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span>  <span class="comment">//import org.springframework.stereotype.Component;  </span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyTestServiceImpl</span>  <span class="keyword">implements</span> <span class="title">IMyTestService</span> </span>&#123;  </span><br><span class="line">      <span class="meta">@Scheduled</span>(cron=<span class="string">"0/5 * *  * * ? "</span>)   <span class="comment">//每5秒执行一次  </span></span><br><span class="line">      <span class="meta">@Override</span>  </span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">myTest</span><span class="params">()</span></span>&#123;  </span><br><span class="line">            System.out.println(<span class="string">"进入测试"</span>);  </span><br><span class="line">      &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>备注：</p>
<ol>
<li>spring的@Scheduled注解需要写在实现类上</li>
<li>定时器的任务方法不能有返回值（如果有返回值，spring初始化的时候会告诉你有个错误、需要设定一个proxytargetclass的某个值为true）</li>
<li>实现类上要有组件的注解@Component</li>
</ol>
<p>参数说明:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">字段 允许值 允许的特殊字符  </span><br><span class="line">秒 0-59 , - * /  </span><br><span class="line">分 0-59 , - * /  </span><br><span class="line">小时 0-23 , - * /  </span><br><span class="line">日期 1-31 , - * ? / L W C  </span><br><span class="line">月份 1-12 或者 JAN-DEC , - * /  </span><br><span class="line">星期 1-7 或者 SUN-SAT , - * ? / L C #  </span><br><span class="line">年（可选） 留空, 1970-2099 , - * /  </span><br><span class="line">表达式意义  </span><br><span class="line">&quot;0 0 12 * * ?&quot; 每天中午12点触发  </span><br><span class="line">&quot;0 15 10 ? * *&quot; 每天上午10:15触发  </span><br><span class="line">&quot;0 15 10 * * ?&quot; 每天上午10:15触发  </span><br><span class="line">&quot;0 15 10 * * ? *&quot; 每天上午10:15触发  </span><br><span class="line">&quot;0 15 10 * * ? 2005&quot; 2005年的每天上午10:15触发  </span><br><span class="line">&quot;0 * 14 * * ?&quot; 在每天下午2点到下午2:59期间的每1分钟触发  </span><br><span class="line">&quot;0 0/5 14 * * ?&quot; 在每天下午2点到下午2:55期间的每5分钟触发  </span><br><span class="line">&quot;0 0/5 14,18 * * ?&quot; 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发  </span><br><span class="line">&quot;0 0-5 14 * * ?&quot; 在每天下午2点到下午2:05期间的每1分钟触发  </span><br><span class="line">&quot;0 10,44 14 ? 3 WED&quot; 每年三月的星期三的下午2:10和2:44触发  </span><br><span class="line">&quot;0 15 10 ? * MON-FRI&quot; 周一至周五的上午10:15触发  </span><br><span class="line">&quot;0 15 10 15 * ?&quot; 每月15日上午10:15触发  </span><br><span class="line">&quot;0 15 10 L * ?&quot; 每月最后一日的上午10:15触发  </span><br><span class="line">&quot;0 15 10 ? * 6L&quot; 每月的最后一个星期五上午10:15触发  </span><br><span class="line">&quot;0 15 10 ? * 6L 2002-2005&quot; 2002年至2005年的每月的最后一个星期五上午10:15触发  </span><br><span class="line">&quot;0 15 10 ? * 6#3&quot; 每月的第三个星期五上午10:15触发  </span><br><span class="line">每天早上6点  </span><br><span class="line">0 6 * * *  </span><br><span class="line">每两个小时  </span><br><span class="line">0 */2 * * *  </span><br><span class="line">晚上11点到早上8点之间每两个小时，早上八点  </span><br><span class="line">0 23-7/2，8 * * *  </span><br><span class="line">每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点  </span><br><span class="line">0 11 4 * 1-3  </span><br><span class="line">1月1日早上4点  </span><br><span class="line">0 4 1 1 *</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Spring/">Spring</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Spring/">Spring</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/5/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/7/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github Card</p>
<div class="github-card" data-github="slamke" data-width="220" data-height="119" data-theme="medium">
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>
  </div>



  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/HDFS/" title="HDFS">HDFS<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hadoop/" title="Hadoop">Hadoop<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hive/" title="Hive">Hive<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/Java/" title="Java">Java<sup>11</sup></a></li>
		  
		
		  
			<li><a href="/categories/Kafka/" title="Kafka">Kafka<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/ML/" title="ML">ML<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Python/" title="Python">Python<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/REST/" title="REST">REST<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Reactor/" title="Reactor">Reactor<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Scala/" title="Scala">Scala<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/Spark/" title="Spark">Spark<sup>27</sup></a></li>
		  
		
		  
			<li><a href="/categories/Spring/" title="Spring">Spring<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/Tomcat/" title="Tomcat">Tomcat<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Web/" title="Web">Web<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/多线程/" title="多线程">多线程<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/数据仓库/" title="数据仓库">数据仓库<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法/" title="算法">算法<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/重构/" title="重构">重构<sup>1</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Spark/" title="Spark">Spark<sup>24</sup></a></li>
			
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/Web/" title="Web">Web<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Spring/" title="Spring">Spring<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Scala/" title="Scala">Scala<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Hive/" title="Hive">Hive<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Session/" title="Session">Session<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Spark-Streaming/" title="Spark Streaming">Spark Streaming<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Cookie/" title="Cookie">Cookie<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/多线程/" title="多线程">多线程<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Spark2-0/" title="Spark2.0">Spark2.0<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Junit/" title="Junit">Junit<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/REST/" title="REST">REST<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Yarn/" title="Yarn">Yarn<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/HDFS/" title="HDFS">HDFS<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/UDF/" title="UDF">UDF<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ML/" title="ML">ML<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="http://slamke.blogspot.com/" target="_blank" title="我的博客">我的博客</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Larry Page in Google. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		<a href="https://github.com/slamke" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		
		
		<a href="mailto:sunke3296@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2018 
		
		<a href="/about" target="_blank" title="Sun Ke">Sun Ke</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
