<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="雁渡寒潭 风吹疏竹">
<meta property="og:url" content="http://slamke.github.io/page/4/index.html">
<meta property="og:site_name" content="雁渡寒潭 风吹疏竹">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雁渡寒潭 风吹疏竹">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://slamke.github.io/page/4/"/>





  <title>雁渡寒潭 风吹疏竹</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">雁渡寒潭 风吹疏竹</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">教练，我想打篮球</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/04/10/流式计算概述和Spark-Streaming-tips/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/04/10/流式计算概述和Spark-Streaming-tips/" itemprop="url">流式计算概述和Spark Streaming tips</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-10T16:05:54+08:00">
                2017-04-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="常规计算引擎分类"><a href="#常规计算引擎分类" class="headerlink" title="常规计算引擎分类"></a>常规计算引擎分类</h2><ol>
<li>批处理<br>• 高吞吐，低延迟<br>• 面向静态数据集合的处理<br>• 分钟甚至小时级别延迟<br>• 比如MR, Spark</li>
<li>流式计算<br>• 面向行级别数据处理<br>• 毫秒级延迟<br>• 比如storm</li>
</ol>
<h2 id="流式计算分类"><a href="#流式计算分类" class="headerlink" title="流式计算分类"></a>流式计算分类</h2><ol>
<li>面向行<br>Apache Flink — 收集一堆数据，然后一行一行处理<br>Storm</li>
<li>面向micro-Batch<br>Spark Streaming — 收集一堆数据，然后一起处理 </li>
</ol>
<h2 id="流式计算通用户环节"><a href="#流式计算通用户环节" class="headerlink" title="流式计算通用户环节"></a>流式计算通用户环节</h2><p>数据源 —&gt; 数据缓存 —&gt; 流式引擎 —&gt; 结果存储</p>
<h2 id="流式计算计算方式"><a href="#流式计算计算方式" class="headerlink" title="流式计算计算方式"></a>流式计算计算方式</h2><ol>
<li>固定窗口<br>Spark Streaming 常规支持的方式</li>
<li><p>滑动窗口( window )</p>
</li>
<li><p>会话计算( mapWithStates )<br>存储Spark Streaming的状态信息（类似session），可以进行过期处理</p>
<h2 id="Spark-Streaming编程要点"><a href="#Spark-Streaming编程要点" class="headerlink" title="Spark Streaming编程要点"></a>Spark Streaming编程要点</h2></li>
</ol>
<blockquote>
<p>Spark Streaming: exactly once delivery<br>特殊情况：故障重算，推测执行等</p>
</blockquote>
<ol>
<li>Monitoring and managing jobs</li>
</ol>
<ul>
<li>where to run the driver?<br><strong>Yarn cluster mode</strong>. Driver will continue to running when the client machine goes down.</li>
<li>How to restart driver ?<br>set up <strong>automatic restart</strong>.<br>In spark configuration (e.g. spark-defaults.conf): </li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.maxAppAttempts=2  // 重试尝试次数</span><br><span class="line">spark.yarn.am.attemptFailuresValidityInterval=1h  // 重置尝试次数的时间</span><br><span class="line">spark.yarn.max.executor.failures=&#123;8 * num_executors&#125;  // executor失败的最大次数</span><br><span class="line">spark.yarn.executor.failuresValidityInterval=1h	// 重置失败的时间</span><br><span class="line">spark.task.maxFailures=8   // task重试次数 默认是4</span><br><span class="line">spark.speculation=true  //预测执行， 前提：task是幂等</span><br></pre></td></tr></table></figure>
<ul>
<li>Summary<br>各种<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">2. Graceful shutting down your streaming app</span><br><span class="line">思路： Thread hooks – Check for an external flag every N seconds</span><br><span class="line"> </span><br><span class="line">``` scala</span><br><span class="line">/** * Stop the execution of the streams, with option of ensuring all received data </span><br><span class="line">	* has been processed. </span><br><span class="line">	*</span><br><span class="line">	* * @param stopSparkContext if true, stops the associated SparkContext. The underlying SparkContext </span><br><span class="line">	* will be stopped regardless of whether this StreamingContext has been </span><br><span class="line">	* started. </span><br><span class="line">	* @param stopGracefully if true, stops gracefully by waiting for the processing of all </span><br><span class="line">	* received data to be completed </span><br><span class="line">	*/ </span><br><span class="line">	def stop(stopSparkContext: Boolean, stopGracefully: Boolean): Unit = &#123;</span><br><span class="line">	receiverTracker.stop(processAllReceivedData) //default is to wait 10 second, grace waits until done jobGenerator.stop(processAllReceivedData) // Will use spark.streaming.gracefulStopTimeout </span><br><span class="line">	jobExecutor.shutdown() </span><br><span class="line">	val terminated = if (processAllReceivedData) &#123; </span><br><span class="line">		jobExecutor.awaitTermination(1, TimeUnit.HOURS) // just a very large period of time </span><br><span class="line">	&#125; else &#123; </span><br><span class="line">		jobExecutor.awaitTermination(2, TimeUnit.SECONDS) </span><br><span class="line">	&#125; </span><br><span class="line">	if (!terminated) &#123; jobExecutor.shutdownNow() </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>How to be graceful?<br>• cmd line<br>– $SPARK_HOME_DIR/bin/spark-submit –master $MASTER_REST_URL –kill $DRIVER_ID<br>– spark.streaming.stopGracefullyOnShutdown=true </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">stopOnShutdown</span></span>(): <span class="type">Unit</span> = &#123; </span><br><span class="line"><span class="keyword">val</span> stopGracefully = conf.getBoolean(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="literal">false</span>) </span><br><span class="line">logInfo(<span class="string">s"Invoking stop(stopGracefully=<span class="subst">$stopGracefully</span>) from shutdown hook"</span>) </span><br><span class="line"><span class="comment">// Do not stop SparkContext, let its own shutdown hook stop it </span></span><br><span class="line">stop(stopSparkContext = <span class="literal">false</span>, stopGracefully = stopGracefully) &#125;</span><br></pre></td></tr></table></figure>
<p>• By marker file<br>– Touch a file when starting the app on HDFS<br>– Remove the file when you want to stop<br>– Separate thread in Spark app, calls </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamingContext.stop(stopSparkContext = <span class="literal">true</span>, stopGracefully = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/04/06/Structured-Streaming介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/04/06/Structured-Streaming介绍/" itemprop="url">Structured Streaming介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-06T13:42:35+08:00">
                2017-04-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="中文入门编程指南"><a href="#中文入门编程指南" class="headerlink" title="中文入门编程指南"></a><a href="https://www.iteblog.com/archives/2084.html" target="_blank" rel="noopener">中文入门编程指南</a></h2><h2 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a><a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" target="_blank" rel="noopener">官方文档</a></h2><h2 id="Real-time-Streaming-ETL-with-Structured-Streaming-in-Apache-Spark-2-1"><a href="#Real-time-Streaming-ETL-with-Structured-Streaming-in-Apache-Spark-2-1" class="headerlink" title="Real-time Streaming ETL with Structured Streaming in Apache Spark 2.1"></a><a href="https://databricks.com/blog/2017/01/19/real-time-streaming-etl-structured-streaming-apache-spark-2-1.html" target="_blank" rel="noopener">Real-time Streaming ETL with Structured Streaming in Apache Spark 2.1</a></h2><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Structured Streaming接口在社区2.0版本发布测试接口，主要暴露最初的设计思路及基本接口，不具备在生产环境使用的能力；2.1版本中Structured Streaming作为主要功能发布，支持Kafka数据源、基于event_time的window及watermark功能，虽然还在Alapha阶段，但从实现的完备程度及反馈来看已具备初步的功能需求。</p>
<h2 id="设计理念及所解决的问题"><a href="#设计理念及所解决的问题" class="headerlink" title="设计理念及所解决的问题"></a>设计理念及所解决的问题</h2><p>从Spark 0.7版本发布DStream接口及Spark Streaming模块以来，Spark具备流式处理功能且在业界有了一系列应用，但依旧存在一些问题，诟病较多的是如下几点：</p>
<ul>
<li>不支持event_time，按照到达绝对时间切分records组成DStream的方式对很多场景不适合</li>
<li>不支持流式window操作</li>
<li>不支持watermark，无法对乱序数据做容错</li>
</ul>
<p>2.1版本的Spark不但解决上述问题，并将Spark Streaming的流处理方式和1.x版本中集中开发的SQL模块、DataFrame\DataSet API相融合，推出Structured Streaming引擎。其设计思路在于将持续不断的上游数据抽象为unbounded table，对流式的处理看作是表中不同部分的数据(complete\append\update mode)进行处理：<br><img src="http://spark.apache.org/docs/latest/img/structured-streaming-stream-as-a-table.png" alt=""><br>从代码层面看，Structured Streaming代码放在sql模块中，与原有SQL的datasource api、logical plan、physical plan做了诸多兼容操作，将流式处理的上游下游分别抽象为Source与Sink，基于DataFrame抽象出输入输出流DataStreamReader、DataStreamWriter。DataStreamReader中打通datasource api，支持多种上游的读取支持，DataStreamWriter中遵循惰性计算的思路实现多种触发操作及不同类型的写出模式。</p>
<h2 id="Demo-for-struct-streaming"><a href="#Demo-for-struct-streaming" class="headerlink" title="Demo for struct streaming"></a>Demo for struct streaming</h2><p>一个完整的struct streaming示例及分布解释如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 与其他spark作业一致，获取build spark session,对应旧版本中的spark context</span></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">  .builder</span><br><span class="line">  .appName(<span class="string">"StructuredNetworkWordCount"</span>)</span><br><span class="line">  .getOrCreate()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="comment">// 创建一个基于stream source的dataframe</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">val</span> lines = spark.readStream</span><br><span class="line">  .format(<span class="string">"socket"</span>)    # 对应基本概念：<span class="type">Source</span></span><br><span class="line">  .option(<span class="string">"host"</span>, host)</span><br><span class="line">  .option(<span class="string">"port"</span>, port)</span><br><span class="line">  .load()</span><br><span class="line"> </span><br><span class="line"><span class="comment">// WordCount逻辑，与dataframe/dataset api用法完全一致，</span></span><br><span class="line"><span class="keyword">val</span> words = lines.as[<span class="type">String</span>].flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">val</span> wordCounts = words.groupBy(<span class="string">"value"</span>).count()</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 调用dataset的writeStream创建写出流，设置对应的sink mode及类型</span></span><br><span class="line"><span class="keyword">val</span> query = wordCounts.writeStream</span><br><span class="line">  .outputMode(<span class="string">"complete"</span>)   # 对应基本概念：<span class="type">Output</span> <span class="type">Mode</span></span><br><span class="line">  .format(<span class="string">"console"</span>)        # 对应基本概念：<span class="type">Sink</span></span><br><span class="line">  .start()</span><br><span class="line"> </span><br><span class="line">query.awaitTermination()</span><br></pre></td></tr></table></figure></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><p>Struct Streaming的输入源，每种输入源对应自己的dataSource实现，当前支持如下三种Source：</p>
<ul>
<li><strong>File Source</strong>: 输入数据源为hdfs目录中的文件，天然支持的文件格式和dataset一致(json csv text parquet)，将文件不断mv至指定目录中作为持续数据源</li>
<li><strong>Kafka Source</strong>: 将kafka作为struct streaming source，目前支持的版本为0.10.0</li>
<li><strong>Socket Source</strong>: 将socket输入数据作为streaming source，只用来做调试和demo使用<h3 id="Output-Mode"><a href="#Output-Mode" class="headerlink" title="Output Mode"></a>Output Mode</h3>Output Mode都是对于每次trigger过后的result table而言的</li>
<li><strong>Complete Mode</strong> : 从开始到目前为止的所有数据视为一张大表，query作用于整个表上的结果整体写入</li>
<li><strong>Append Mode</strong> : 从上次trigger到目前为止，不会在发生变化的数据append到最终的sink端</li>
<li><strong>Update Mode</strong> : 从上次trigger到目前为止，发生变化的条目写入到最终的sink端</li>
</ul>
<p>简单用自带的StructuredNetworkWordCountWindowed实例对比下Complete mode与Update Mode:<br>数据输入：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[liyuanjian@MacBook~Pro ~]$ nc -l 9999</span><br><span class="line">apache spark</span><br><span class="line">apache hadoop</span><br><span class="line">baidu inf spark</span><br></pre></td></tr></table></figure></p>
<p>Complete mode output:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------+-----+</span><br><span class="line">| value|count|</span><br><span class="line">+------+-----+</span><br><span class="line">|apache| 1|</span><br><span class="line">| spark| 1|</span><br><span class="line">+------+-----+</span><br><span class="line"> </span><br><span class="line">+------+-----+</span><br><span class="line">| value|count|</span><br><span class="line">+------+-----+</span><br><span class="line">|apache| 2|</span><br><span class="line">|hadoop| 1|</span><br><span class="line">| spark| 1|</span><br><span class="line">+------+-----+</span><br><span class="line"> </span><br><span class="line">+------+-----+</span><br><span class="line">| value|count|</span><br><span class="line">+------+-----+</span><br><span class="line">| baidu| 1|</span><br><span class="line">|apache| 2|</span><br><span class="line">|hadoop| 1|</span><br><span class="line">| spark| 2|</span><br><span class="line">| inf| 1|</span><br><span class="line">+------+-----+</span><br></pre></td></tr></table></figure></p>
<p>Update mode output:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+------+-----+</span><br><span class="line">| value|count|</span><br><span class="line">+------+-----+</span><br><span class="line">|apache| 1|</span><br><span class="line">| spark| 1|</span><br><span class="line">+------+-----+</span><br><span class="line"> </span><br><span class="line">+------+-----+</span><br><span class="line">| value|count|</span><br><span class="line">+------+-----+</span><br><span class="line">|apache| 2|</span><br><span class="line">|hadoop| 1|</span><br><span class="line">+------+-----+</span><br><span class="line"> </span><br><span class="line">+-----+-----+</span><br><span class="line">|value|count|</span><br><span class="line">+-----+-----+</span><br><span class="line">|baidu| 1|</span><br><span class="line">| inf| 1|</span><br><span class="line">|spark| 2|</span><br><span class="line">+-----+-----+</span><br></pre></td></tr></table></figure></p>
<h3 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h3><p>作为struct streaming的下游抽象，sink代表将最终处理完成的dataframe写出的方式，目前支持：</p>
<ol>
<li><strong>File sink</strong> : 将数据写入hdfs目录，可以支持带partition的table写入</li>
<li><strong>Console sink</strong> : 将数据直接调用dataframe.show()打印在stdout，调试作用，demo中使用的都是console sink</li>
<li><strong>Memory sink</strong> : 将所有下游存储在driver的内存中，抽象为一张表，也只能做调试使用</li>
<li><strong>Foreach sink</strong> : 依赖用户实现ForeachWriter接口配合使用，foreach sink中对每次触发的dataframe，按逐个partition调用ForeachWriter的接口进行处理，可以实现ForeachWriter写入任何需要的下游存储或处理系统，接口如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ForeachWriter</span>[<span class="type">T</span>] <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Move this to org.apache.spark.sql.util or consolidate this with batch API.</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Called when starting to process one partition of new data in the executor. The `version` is</span></span><br><span class="line"><span class="comment">   * for data deduplication when there are failures. When recovering from a failure, some data may</span></span><br><span class="line"><span class="comment">   * be generated multiple times but they will always have the same version.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * If this method finds using the `partitionId` and `version` that this partition has already been</span></span><br><span class="line"><span class="comment">   * processed, it can return `false` to skip the further data processing. However, `close` still</span></span><br><span class="line"><span class="comment">   * will be called for cleaning up resources.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param partitionId the partition id.</span></span><br><span class="line"><span class="comment">   * @param version a unique id for data deduplication.</span></span><br><span class="line"><span class="comment">   * @return `true` if the corresponding partition and version id should be processed. `false`</span></span><br><span class="line"><span class="comment">   *         indicates the partition should be skipped.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(partitionId: <span class="type">Long</span>, version: <span class="type">Long</span>): <span class="type">Boolean</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Called to process the data in the executor side. This method will be called only when `open`</span></span><br><span class="line"><span class="comment">   * returns `true`.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(value: <span class="type">T</span>): <span class="type">Unit</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Called when stopping to process one partition of new data in the executor side. This is</span></span><br><span class="line"><span class="comment">   * guaranteed to be called either `open` returns `true` or `false`. However,</span></span><br><span class="line"><span class="comment">   * `close` won't be called in the following cases:</span></span><br><span class="line"><span class="comment">   *  - JVM crashes without throwing a `Throwable`</span></span><br><span class="line"><span class="comment">   *  - `open` throws a `Throwable`.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param errorOrNull the error thrown during processing data or null if there was no error.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(errorOrNull: <span class="type">Throwable</span>): <span class="type">Unit</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h3><p>和其他流式系统一样，基于滑动时间窗的数据统计、聚合是必不可少的需求，2.1实现了基于event-time的window定义，接口如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Bucketize rows into one or more time windows given a timestamp specifying column. Window</span></span><br><span class="line"><span class="comment"> * starts are inclusive but the window ends are exclusive, e.g. 12:05 will be in the window</span></span><br><span class="line"><span class="comment"> * [12:05,12:10) but not in [12:00,12:05). Windows can support microsecond precision. Windows in</span></span><br><span class="line"><span class="comment"> * the order of months are not supported. The windows start beginning at 1970-01-01 00:00:00 UTC.</span></span><br><span class="line"><span class="comment"> * The following example takes the average stock price for a one minute window every 10 seconds:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &#123;&#123;&#123;</span></span><br><span class="line"><span class="comment"> *   val df = ... // schema =&gt; timestamp: TimestampType, stockId: StringType, price: DoubleType</span></span><br><span class="line"><span class="comment"> *   df.groupBy(window($"time", "1 minute", "10 seconds"), $"stockId")</span></span><br><span class="line"><span class="comment"> *     .agg(mean("price"))</span></span><br><span class="line"><span class="comment"> * &#125;&#125;&#125;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The windows will look like:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &#123;&#123;&#123;</span></span><br><span class="line"><span class="comment"> *   09:00:00-09:01:00</span></span><br><span class="line"><span class="comment"> *   09:00:10-09:01:10</span></span><br><span class="line"><span class="comment"> *   09:00:20-09:01:20 ...</span></span><br><span class="line"><span class="comment"> * &#125;&#125;&#125;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * For a streaming query, you may use the function `current_timestamp` to generate windows on</span></span><br><span class="line"><span class="comment"> * processing time.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param timeColumn The column or the expression to use as the timestamp for windowing by time.</span></span><br><span class="line"><span class="comment"> *                   The time column must be of TimestampType.</span></span><br><span class="line"><span class="comment"> * @param windowDuration A string specifying the width of the window, e.g. `10 minutes`,</span></span><br><span class="line"><span class="comment"> *                       `1 second`. Check [[org.apache.spark.unsafe.types.CalendarInterval]] for</span></span><br><span class="line"><span class="comment"> *                       valid duration identifiers. Note that the duration is a fixed length of</span></span><br><span class="line"><span class="comment"> *                       time, and does not vary over time according to a calendar. For example,</span></span><br><span class="line"><span class="comment"> *                       `1 day` always means 86,400,000 milliseconds, not a calendar day.</span></span><br><span class="line"><span class="comment"> * @param slideDuration A string specifying the sliding interval of the window, e.g. `1 minute`.</span></span><br><span class="line"><span class="comment"> *                      A new window will be generated every `slideDuration`. Must be less than</span></span><br><span class="line"><span class="comment"> *                      or equal to the `windowDuration`. Check</span></span><br><span class="line"><span class="comment"> *                      [[org.apache.spark.unsafe.types.CalendarInterval]] for valid duration</span></span><br><span class="line"><span class="comment"> *                      identifiers. This duration is likewise absolute, and does not vary</span></span><br><span class="line"><span class="comment"> *                     according to a calendar.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @group datetime_funcs</span></span><br><span class="line"><span class="comment"> * @since 2.0.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Experimental</span></span><br><span class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">window</span></span>(timeColumn: <span class="type">Column</span>, windowDuration: <span class="type">String</span>, slideDuration: <span class="type">String</span>): <span class="type">Column</span> = &#123;</span><br><span class="line">  window(timeColumn, windowDuration, slideDuration, <span class="string">"0 second"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>window通常与groupBy算子连用，通过设置dataframe中的timeColumn，windowDuration(window大小)，sildeDuration(步长)，来定义整个window的行为，如windowDuration = 10min, slideDuration = 5min，则代表由event-time触发每5分钟计算一次，计算的对象是当前window中10min的数据</p>
<h3 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h3><p>接上述window的介绍，对于任何基于window\event-time的聚合场景，我们都需要考虑对于乱序的过期event-time数据到达的处理行为。watermark用来给用户提供一个接口，让用户能够定义”比当前处理时间慢多久的数据可以丢弃，不再处理”，祥设文档参见：<a href="https://docs.google.com/document/d/1z-Pazs5v4rA31azvmYhu4I5xwqaNQl6ZLIS03xhkfCQ/edit#heading=h.yx3tjr1mrnl2" target="_blank" rel="noopener">https://docs.google.com/document/d/1z-Pazs5v4rA31azvmYhu4I5xwqaNQl6ZLIS03xhkfCQ/edit#heading=h.yx3tjr1mrnl2</a></p>
<p><img src="http://spark.apache.org/docs/latest/img/structured-streaming-watermark.png" alt=""></p>
<ul>
<li>watermark的计算规则</li>
</ul>
<ol>
<li>在每次trigger触发计算时，先找到trigger data中的最大(近)event-time</li>
<li>trigger结束后，   <code>new watermark = MAX(event-time before trigger, max event-time in trigger[步骤1]) - threashold</code><br>watermark的限制<br>watermark操作只能在logical plan中有一个，而且只能应用在从sink出发的单child关系链，简单理解就是处理不了复杂的多留join、union的各自设置watermark</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/30/如何在Spark平台搭建ThriftServer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/30/如何在Spark平台搭建ThriftServer/" itemprop="url">如何在Spark平台搭建ThriftServer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-30T10:58:04+08:00">
                2017-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Thrift-JDBC-Server描述"><a href="#Thrift-JDBC-Server描述" class="headerlink" title="Thrift JDBC Server描述"></a>Thrift JDBC Server描述</h2><p>Thrift JDBC Server使用的是HIVE0.12的HiveServer2实现。能够使用Spark或者hive0.12版本的beeline脚本与JDBC Server进行交互使用。Thrift JDBC Server默认监听端口是10000。</p>
<h2 id="使用Thrift-JDBC-Server前需要注意："><a href="#使用Thrift-JDBC-Server前需要注意：" class="headerlink" title="使用Thrift JDBC Server前需要注意："></a>使用Thrift JDBC Server前需要注意：</h2><p>1、将<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">说明: hive-site.xml配置有meta信息存储的MySQL路径</span><br><span class="line"></span><br><span class="line">2、需要在$SPARK_HOME/conf/spark-env.sh中的SPARK_CLASSPATH添加jdbc驱动的jar包</span><br><span class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:/home/hadoop/software/mysql-connector-java-5.1.27-bin.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Thrift JDBC Server/beeline启动</span><br><span class="line"></span><br><span class="line">1. 启动Thrift JDBC Server：默认端口是10000</span><br><span class="line"></span><br><span class="line">cd $SPARK_HOME/sbin</span><br><span class="line">start-thriftserver.sh</span><br><span class="line">&gt; 如何修改Thrift JDBC Server的默认监听端口号？借助于--hiveconf</span><br><span class="line">start-thriftserver.sh  --hiveconf hive.server2.thrift.port=14000</span><br><span class="line"></span><br><span class="line">Demo:</span><br><span class="line"></span><br><span class="line">``` shell</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">./sbin/start-thriftserver.sh \</span><br><span class="line">        --hiveconf hive.exec.mode.local.auto=true  \</span><br><span class="line">        --hiveconf hive.auto.convert.join=true     \</span><br><span class="line">        --hiveconf hive.mapjoin.smalltable.filesize=50000000 \</span><br><span class="line">        --name thriftserver    \</span><br><span class="line">        --master yarn-client \</span><br><span class="line">        --driver-cores    5   \</span><br><span class="line">        --driver-memory   5G  \</span><br><span class="line">        --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \</span><br><span class="line">        --conf spark.scheduler.mode=FAIR \</span><br><span class="line">        --conf spark.kryoserializer.buffer.max.mb=1024 \</span><br><span class="line">        --conf spark.storage.memoryFraction=0.2</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li>启动beeline<br>cd $SPARK_HOME/bin<br>beeline -u jdbc:hive2://hadoop000:10000</li>
</ol>
<p>Demo:</p>
<pre><code class="shell"><span class="meta">$</span> ./bin/beeline
Beeline version 1.2.1.spark2 by Apache Hive
<span class="meta">beeline&gt;</span> !connect jdbc:hive2://localhost:10000
</code></pre>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/29/Scala代码规范/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/29/Scala代码规范/" itemprop="url">Scala代码规范</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-29T18:00:07+08:00">
                2017-03-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Scala/" itemprop="url" rel="index">
                    <span itemprop="name">Scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="格式与命名"><a href="#格式与命名" class="headerlink" title="格式与命名"></a>格式与命名</h2><p>1) 代码格式<br>用两个空格缩进。避免每行长度超过100列。在两个方法、类、对象定义之间使用一个空白行。</p>
<p>2) 优先考虑使用val，而非var。</p>
<p>3) 当引入多个包时，使用花括号：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jxl.write.&#123;<span class="type">WritableCell</span>, <span class="type">Number</span>, <span class="type">Label</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>当引入的包超过6个时，应使用通配符_：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.scalatest.events._</span><br></pre></td></tr></table></figure></p>
<p>4) 若方法暴露为接口，则返回类型应该显式声明。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span></span>(conn: <span class="type">Connection</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  executeCommand(conn, sqlStatement) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Right</span>(result) =&gt; result</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Left</span>(_) =&gt; <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>5) 集合的命名规范<br>xs, ys, as, bs等作为某种Sequence对象的名称；<br>x, y, z, a, b作为sequence元素的名称。<br>h作为head的名称，t作为tail的名称。</p>
<p>6) 避免对简单的表达式采用花括号；<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//suggestion</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span></span>(x: <span class="type">Int</span>) = x * x</span><br><span class="line"></span><br><span class="line"><span class="comment">//avoid</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span></span>(x: <span class="type">Int</span>) = &#123;</span><br><span class="line">     x * x</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>7) 泛型类型参数的命名虽然没有限制，但建议遵循如下规则：<br>A            代表一个简单的类型，例如List[A]<br>B, C, D      用于第2、第3、第4等类型。例如：<br>                 class List[A] {<br>                     def map<a href="f: A =&gt; B" target="_blank" rel="noopener">B</a>: List[B] = …<br>                 }<br> N           代表数值类型</p>
<p><strong>注意：</strong>在Java中，通常以K、V代表Map的key与value，但是在Scala中，更倾向于使用A、B代表Map的key与value。</p>
<h2 id="语法特性"><a href="#语法特性" class="headerlink" title="语法特性"></a>语法特性</h2><p>1) 定义隐式类时，应该将构造函数的参数声明为val。</p>
<p>2) <strong>使用for表达式；如果需要条件表达式，应将条件表达式写到for comprehension中</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//not good</span></span><br><span class="line"><span class="keyword">for</span> (file &lt;- files) &#123;</span><br><span class="line">     <span class="keyword">if</span> (hasSoundFileExtension(file) &amp;&amp; !soundFileIsLong(file)) &#123;</span><br><span class="line">        soundFiles += file</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//better</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">     file &lt;- files</span><br><span class="line">     <span class="keyword">if</span> hasSoundFileExtension(file)</span><br><span class="line">     <span class="keyword">if</span> !soundFileIsLong(file)</span><br><span class="line">&#125; <span class="keyword">yield</span> file</span><br></pre></td></tr></table></figure></p>
<p><strong>通常情况下，我们应优先考虑filter, map, flatMap等操作，而非for comprehension</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//best</span></span><br><span class="line">files.filter(hasSourceFileExtension).filterNot(soundFileIsLong)</span><br></pre></td></tr></table></figure></p>
<p>3) 避免使用isInstanceOf，而是使用模式匹配，尤其是在处理比较复杂的类型判断时，使用模式匹配的可读性更好。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//avoid</span></span><br><span class="line"><span class="keyword">if</span> (x.isInstanceOf[<span class="type">Foo</span>]) &#123; do something …</span><br><span class="line"></span><br><span class="line"><span class="comment">//suggest</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isPerson</span></span>(x: <span class="type">Any</span>): <span class="type">Boolean</span> = x <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> p: <span class="type">Person</span> =&gt; <span class="literal">true</span></span><br><span class="line">  <span class="keyword">case</span> _ =&gt; <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>4) 以下情况使用abstract class，而不是trait：</p>
<ul>
<li>想要创建一个需要构造函数参数的基类</li>
<li>代码可能会被Java代码调用</li>
</ul>
<p>5) <strong>如果希望trait只能被某个类（及其子类）extend，应该使用self type</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">MyTrait</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>: <span class="type">BaseType</span> =&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果希望对扩展trait的类做更多限制，可以在self type后增加更多对trait的混入：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">WarpCore</span> </span>&#123;</span><br><span class="line">     <span class="keyword">this</span>: <span class="type">Starship</span> <span class="keyword">with</span> <span class="type">WarpCoreEjector</span> <span class="keyword">with</span> <span class="type">FireExtinguisher</span> =&gt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// this works</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Enterprise</span> <span class="keyword">extends</span> <span class="title">Starship</span></span></span><br><span class="line"><span class="class">    <span class="keyword">with</span> <span class="title">WarpCore</span></span></span><br><span class="line"><span class="class">    <span class="keyword">with</span> <span class="title">WarpCoreEjector</span></span></span><br><span class="line"><span class="class">    <span class="keyword">with</span> <span class="title">FireExtinguisher</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">won</span>'<span class="title">t</span> <span class="title">compile</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">Enterprise</span> <span class="keyword">extends</span> <span class="title">Starship</span></span></span><br><span class="line"><span class="class">     <span class="keyword">with</span> <span class="title">WarpCore</span></span></span><br><span class="line"><span class="class">     <span class="keyword">with</span> <span class="title">WarpCoreEjector</span></span></span><br></pre></td></tr></table></figure></p>
<p><strong>如果要限制扩展trait的类必须定义相关的方法，可以在self type中定义方法，这称之为structural type</strong>（类似动态语言的鸭子类型）:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">WarpCore</span> </span>&#123;</span><br><span class="line">     <span class="keyword">this</span>: &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">ejectWarpCore</span></span>(password: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">startWarpCore</span></span>: <span class="type">Unit</span></span><br><span class="line">     &#125; =&gt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Starship</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">Enterprise</span> <span class="keyword">extends</span> <span class="title">Starship</span> <span class="keyword">with</span> <span class="title">WarpCore</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">ejectWarpCore</span></span>(password: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">          <span class="keyword">if</span> (password == <span class="string">"password"</span>) &#123; println(<span class="string">"core ejected"</span>); <span class="literal">true</span> &#125; <span class="keyword">else</span> <span class="literal">false</span> &#125;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">startWarpCore</span> </span>&#123; println(<span class="string">"core started"</span>) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>6) <strong>对于较长的类型名称，在特定上下文中，以不影响阅读性和表达设计意图为前提，建议使用类型别名</strong>，它可以帮助程序变得更简短。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcurrentPool</span>[<span class="type">K</span>, <span class="type">V</span>] </span>&#123;</span><br><span class="line">   <span class="class"><span class="keyword">type</span> <span class="title">Queue</span> </span>= <span class="type">ConcurrentLinkedQueue</span>[<span class="type">V</span>]</span><br><span class="line">   <span class="class"><span class="keyword">type</span> <span class="title">Map</span>   </span>= <span class="type">ConcurrentHashMap</span>[<span class="type">K</span>, <span class="type">Queue</span>]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>7) 如果要使用隐式参数，应尽量使用自定义类型作为隐式参数的类型，而避免过于宽泛的类型，如String，Int，Boolean等。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//suggestion</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxOfList</span></span>[<span class="type">T</span>](elements: <span class="type">List</span>[<span class="type">T</span>])</span><br><span class="line">         (<span class="keyword">implicit</span> orderer: <span class="type">T</span> =&gt; <span class="type">Ordered</span>[<span class="type">T</span>]): <span class="type">T</span> =</span><br><span class="line">   elements <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">List</span>() =&gt;</span><br><span class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"empty list!"</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">List</span>(x) =&gt; x</span><br><span class="line">      <span class="keyword">case</span> x :: rest =&gt;</span><br><span class="line">         <span class="keyword">val</span> maxRest = maxListImpParm(rest)(orderer)</span><br><span class="line">         <span class="keyword">if</span> (orderer(x) &gt; maxRest) x</span><br><span class="line">         <span class="keyword">else</span> maxRest</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//avoid</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxOfListPoorStyle</span></span>[<span class="type">T</span>](elements: <span class="type">List</span>[<span class="type">T</span>])</span><br><span class="line">        (<span class="keyword">implicit</span> orderer: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">Boolean</span>): <span class="type">T</span></span><br></pre></td></tr></table></figure></p>
<p>8) <strong>对于异常的处理，Scala除了提供Java风格的try…catch…finally之外，还提供了allCatch.opt、Try…Success…Failure以及Either…Right…Left等风格的处理方式</strong>。其中，Try是2.10提供的语法。根据不同的场景选择不同风格：</p>
<ul>
<li><p>优先选择Try风格。Try很好地支持模式匹配，它兼具Option与Either的特点，因而既提供了集合的语义，又支持模式匹配，又提供了getOrElse()方法。同时，它还可以组合多个Try，并支持运用for combination。例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> z = <span class="keyword">for</span> &#123;</span><br><span class="line">    a &lt;- <span class="type">Try</span>(x.toInt) </span><br><span class="line">    b &lt;- <span class="type">Try</span>(y.toInt)</span><br><span class="line">&#125; <span class="keyword">yield</span> a * b</span><br><span class="line"><span class="keyword">val</span> answer = z.getOrElse(<span class="number">0</span>) * <span class="number">2</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>如果希望清楚的表现非此即彼的特性，应考虑使用Either。注意，约定成俗下，我们习惯将正确的结果放在Either的右边（Right既表示右边，又表示正确）</p>
</li>
<li><p>如果希望将异常情况处理为None，则应考虑使用allCatch.opt。例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.util.control.<span class="type">Exception</span>._</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readTextFile</span></span>(f: <span class="type">String</span>): <span class="type">Option</span>[<span class="type">List</span>[<span class="type">String</span>]] =     </span><br><span class="line">    allCatch.opt(<span class="type">Source</span>.fromFile(f).getLines.toList)</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果希望在执行后释放资源，从而需要使用finally时，考虑try…catch…finally，或者结合try…catch…finally与Either。例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">executeQuery</span></span>(conn: <span class="type">Connection</span>, sql: <span class="type">String</span>): <span class="type">Either</span>[<span class="type">SQLException</span>, <span class="type">ResultSet</span>] = &#123;</span><br><span class="line">  <span class="keyword">var</span> stmt: <span class="type">Statement</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> rs: <span class="type">ResultSet</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    stmt = conn.createStatement()</span><br><span class="line">    rs = stmt.executeQuery(sql)</span><br><span class="line">    <span class="type">Right</span>(rs)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">SQLException</span> =&gt; &#123;</span><br><span class="line">      e.printStackTrace()</span><br><span class="line">      <span class="type">Left</span>(e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (rs != <span class="literal">null</span>) rs.close()</span><br><span class="line">      <span class="keyword">if</span> (stmt != <span class="literal">null</span>) stmt.close()</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">SQLException</span> =&gt; e.printStackTrace()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>为避免重复，还应考虑引入Load Pattern。 </p>
<h2 id="编码模式"><a href="#编码模式" class="headerlink" title="编码模式"></a>编码模式</h2><p>1) <strong>Loan Pattern: 确保打开的资源（如文件、数据库连接）能够在操作完毕后被安全的释放</strong>。</p>
<p>Loan Pattern的通用格式如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">using</span></span>[<span class="type">A</span>](r : <span class="type">Resource</span>)(f : <span class="type">Resource</span> =&gt; <span class="type">A</span>) : <span class="type">A</span> =</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">        f(r)</span><br><span class="line">   &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        r.dispose()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<p>这个格式针对Resource类型进行操作。还有一种做法是：只要实现了close方法，都可以运用Loan Pattern：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">using</span></span>[<span class="type">A</span> &lt;: <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>():<span class="type">Unit</span>, <span class="type">B</span>][resource: <span class="type">A</span>](f: <span class="type">A</span> =&gt; <span class="type">B</span>): <span class="type">B</span> = </span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">          f(resource)</span><br><span class="line">     &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          resource.close()</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure></p>
<p>以FileSource为例：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">using(io.<span class="type">Source</span>.fromFile(<span class="string">"example.txt"</span>)) &#123; </span><br><span class="line">    source =&gt; &#123;</span><br><span class="line">        <span class="keyword">for</span> (line &lt;- source.getLines) &#123;</span><br><span class="line">            println(line)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>2) <strong>Cake Pattern: 利用self type实现依赖注入</strong></p>
<p>例如，对于DbAccessor而言，需要提供不同的DbConnectionFactory来创建连接，从而访问不同的Data Source。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">DbConnectionFactory</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">createDbConnection</span></span>: <span class="type">Connection</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">SybaseDbConnectionFactory</span> <span class="keyword">extends</span> <span class="title">DbConnectionFactory…</span></span></span><br><span class="line"><span class="class"><span class="title">trait</span> <span class="title">MySQLDbConnectionFactory</span> <span class="keyword">extends</span> <span class="title">DbConnectionFactory…</span></span></span><br></pre></td></tr></table></figure></p>
<p>运用Cake Pattern，DbAccessor的定义应该为：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">DbAccessor</span> </span>&#123;</span><br><span class="line">     <span class="keyword">this</span>: <span class="type">DbConnectionFactory</span> =&gt; </span><br><span class="line"></span><br><span class="line">     <span class="comment">//…</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>由于DbAccessor使用了self type，因此可以在DbAccessor中调用DbConnectionFactory的方法createDbConnection()。客户端在创建DbAccessor时，可以根据需要选择混入的DbConnectionFactory：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sybaseDbAccessor = <span class="keyword">new</span> <span class="type">DbAccessor</span> <span class="keyword">with</span> <span class="type">SybaseDbConnectionFactory</span></span><br></pre></td></tr></table></figure></p>
<p>当然，也可以定义object：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SybaseDbAccessor</span> <span class="keyword">extends</span> <span class="title">DbAccessor</span> <span class="keyword">with</span> <span class="title">SybaseDbConnectionFactory</span></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">MySQLDbAccessor</span> <span class="keyword">extends</span> <span class="title">DbAccessor</span> <span class="keyword">with</span> <span class="title">MySQLDbConnectionFactory</span></span></span><br></pre></td></tr></table></figure></p>
<h2 id="编码风格"><a href="#编码风格" class="headerlink" title="编码风格"></a>编码风格</h2><p>1) <strong>尽可能直接在函数定义的地方使用模式匹配。</strong>例如，在下面的写法中，match应该被折叠起来(collapse):<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list map &#123; item =&gt;   </span><br><span class="line">     item <span class="keyword">match</span> &#123;     </span><br><span class="line">          <span class="keyword">case</span> <span class="type">Some</span>(x) =&gt; x     </span><br><span class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">default</span>   </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>用下面的写法替代：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list map &#123;</span><br><span class="line">   <span class="keyword">case</span> <span class="type">Some</span>(x) =&gt; x</span><br><span class="line">   <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">default</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>它很清晰的表达了 list中的元素都被映射，间接的方式让人不容易明白。此时，<strong>传入map的函数实则为partial function</strong>。 </p>
<p>2) <strong>避免使用null，而应该使用Option的None</strong>。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">CopyBytes</span> <span class="keyword">extends</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">     <span class="keyword">var</span> in = <span class="type">None</span>: <span class="type">Option</span>[<span class="type">FileInputStream</span>]</span><br><span class="line">     <span class="keyword">var</span> out = <span class="type">None</span>: <span class="type">Option</span>[<span class="type">FileOutputStream</span>]</span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">          in = <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">FileInputStream</span>(<span class="string">"/tmp/Test.class"</span>))</span><br><span class="line">          out = <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">FileOutputStream</span>(<span class="string">"/tmp/Test.class.copy"</span>))</span><br><span class="line">          <span class="keyword">var</span> c = <span class="number">0</span></span><br><span class="line">          <span class="keyword">while</span> (&#123;c = in.get.read; c != −<span class="number">1</span>&#125;) &#123;</span><br><span class="line">             out.get.write(c)</span><br><span class="line">    &#125;</span><br><span class="line">     &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; e.printStackTrace</span><br><span class="line">     &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          println(<span class="string">"entered finally ..."</span>)</span><br><span class="line">          <span class="keyword">if</span> (in.isDefined) in.get.close</span><br><span class="line">          <span class="keyword">if</span> (out.isDefined) out.get.close</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>方法的返回值也要避免返回Null。应考虑返回Option，Either，或者Try。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.util.&#123;<span class="type">Try</span>, <span class="type">Success</span>, <span class="type">Failure</span>&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readTextFile</span></span>(filename: <span class="type">String</span>): <span class="type">Try</span>[<span class="type">List</span>[<span class="type">String</span>]] = &#123; </span><br><span class="line">    <span class="type">Try</span>(io.<span class="type">Source</span>.fromFile(filename).getLines.toList</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> filename = <span class="string">"/etc/passwd"</span> </span><br><span class="line">readTextFile(filename) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Success</span>(lines) =&gt; lines.foreach(println)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(f) =&gt; println(f) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>3) <strong>若在Class中需要定义常量，应将其定义为val，并将其放在该类的伴生对象中</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pizza</span> (<span class="params">var crustSize: <span class="type">Int</span>, var crustType: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(crustSize: <span class="type">Int</span>) &#123;</span><br><span class="line">          <span class="keyword">this</span>(crustSize, <span class="type">Pizza</span>.<span class="type">DEFAULT_CRUST_TYPE</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(crustType: <span class="type">String</span>) &#123;</span><br><span class="line">          <span class="keyword">this</span>(<span class="type">Pizza</span>.<span class="type">DEFAULT_CRUST_SIZE</span>, crustType)</span><br><span class="line">     &#125;</span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>() &#123;</span><br><span class="line">          <span class="keyword">this</span>(<span class="type">Pizza</span>.<span class="type">DEFAULT_CRUST_SIZE</span>, <span class="type">Pizza</span>.<span class="type">DEFAULT_CRUST_TYPE</span>)</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span> </span>= <span class="string">s"A <span class="subst">$crustSize</span> inch pizza with a <span class="subst">$crustType</span> crust"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Pizza</span> </span>&#123;</span><br><span class="line">     <span class="keyword">val</span> <span class="type">DEFAULT_CRUST_SIZE</span> = <span class="number">12</span></span><br><span class="line">     <span class="keyword">val</span> <span class="type">DEFAULT_CRUST_TYPE</span> = <span class="string">"THIN"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>4) 合理为构造函数或方法提供默认值。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Socket</span> (<span class="params">val timeout: <span class="type">Int</span> = 10000</span>)</span></span><br></pre></td></tr></table></figure></p>
<p>5) 如果需要返回多个值时，应返回tuple。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStockInfo</span> </span>= &#123;</span><br><span class="line">     <span class="comment">//</span></span><br><span class="line">     (<span class="string">"NFLX"</span>, <span class="number">100.00</span>, <span class="number">101.00</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>6) 作为访问器的方法，如果没有副作用，在声明时建议定义为没有括号。</p>
<p>例如，Scala集合库提供的scala.collection.immutable.Queue中，dequeue方法没有副作用，声明时就没有括号：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.immutable.<span class="type">Queue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> q = <span class="type">Queue</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> value = q.dequeue</span><br></pre></td></tr></table></figure></p>
<p>7) <strong>将包的公有代码（常量、枚举、类型定义、隐式转换等）放到package object中</strong>。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.agiledon.myapp</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> <span class="class"><span class="keyword">object</span> <span class="title">model</span> </span>&#123;</span><br><span class="line">     <span class="comment">// field</span></span><br><span class="line">     <span class="keyword">val</span> <span class="type">MAGIC_NUM</span> = <span class="number">42</span> <span class="number">182</span> | <span class="type">Chapter</span> <span class="number">6</span>: <span class="type">Objects</span></span><br><span class="line">￼</span><br><span class="line">     <span class="comment">// method</span></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">echo</span></span>(a: <span class="type">Any</span>) &#123; println(a) &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// enumeration</span></span><br><span class="line">     <span class="class"><span class="keyword">object</span> <span class="title">Margin</span> <span class="keyword">extends</span> <span class="title">Enumeration</span> </span>&#123;</span><br><span class="line">          <span class="class"><span class="keyword">type</span> <span class="title">Margin</span> </span>= <span class="type">Value</span></span><br><span class="line">          <span class="keyword">val</span> <span class="type">TOP</span>, <span class="type">BOTTOM</span>, <span class="type">LEFT</span>, <span class="type">RIGHT</span> = <span class="type">Value</span></span><br><span class="line">     &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// type definition</span></span><br><span class="line">     <span class="class"><span class="keyword">type</span> <span class="title">MutableMap</span>[<span class="type">K</span>, <span class="type">V</span>] </span>= scala.collection.mutable.<span class="type">Map</span>[<span class="type">K</span>, <span class="type">V</span>]</span><br><span class="line">     <span class="keyword">val</span> <span class="type">MutableMap</span> = scala.collection.mutable.<span class="type">Map</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>8) 建议将package object放到与包对象命名空间一致的目录下，并命名为package.scala。以model为例，package.scala文件应放在：<br>+– com<br>     +– agiledon<br>          +– myapp<br>               +– model<br>                    +– package.scala</p>
<p>9) 若有多个样例类属于同一类型，应共同继承自一个sealed trait。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">Message</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">GetCustomers</span> <span class="keyword">extends</span> <span class="title">Message</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">GetOrders</span> <span class="keyword">extends</span> <span class="title">Message</span></span></span><br></pre></td></tr></table></figure></p>
<p><strong>注</strong>：这里的sealed，表示trait的所有实现都必须声明在定义trait的文件中。</p>
<p>10) <strong>考虑使用renaming clause来简化代码。例如，替换被频繁使用的长名称方法</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="type">System</span>.out.&#123;println =&gt; p&#125;</span><br><span class="line"></span><br><span class="line">p(<span class="string">"hallo scala"</span>)</span><br><span class="line">p(<span class="string">"input"</span>)</span><br></pre></td></tr></table></figure></p>
<p>11) <strong>在遍历Map对象或者Tuple的List时，且需要访问map的key和value值时，优先考虑采用Partial Function</strong>，而非使用_1和_2的形式。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dollar = <span class="type">Map</span>(<span class="string">"China"</span> -&gt; <span class="string">"CNY"</span>, <span class="string">"US"</span> -&gt; <span class="string">"DOL"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//perfer</span></span><br><span class="line">dollar.foreach &#123;</span><br><span class="line">     <span class="keyword">case</span> (country, currency) =&gt; println(<span class="string">s"<span class="subst">$country</span> -&gt; <span class="subst">$currency</span>"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//avoid</span></span><br><span class="line">dollar.foreach ( x =&gt; println(<span class="string">s"<span class="subst">$x</span>._1 -&gt; <span class="subst">$x</span>._2"</span>) )</span><br></pre></td></tr></table></figure></p>
<p>或者，考虑使用for comprehension：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ((country, currency) &lt;- dollar) println(<span class="string">s"<span class="subst">$country</span> -&gt; <span class="subst">$currency</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<p>12) 遍历集合对象时，如果需要获得并操作集合对象的下标，不要使用如下方式：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> l = <span class="type">List</span>(<span class="string">"zero"</span>, <span class="string">"one"</span>, <span class="string">"two"</span>, <span class="string">"three"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">0</span> until l.length) <span class="keyword">yield</span> (i, l(i))</span><br></pre></td></tr></table></figure></p>
<p>而应该使用zipWithIndex方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ((number, index) &lt;- l.zipWithIndex) <span class="keyword">yield</span> (index, number)</span><br></pre></td></tr></table></figure></p>
<p>或者：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l.zipWithIndex.map(x =&gt; (x._2, x._1))</span><br></pre></td></tr></table></figure></p>
<p>当然，如果需要将索引值放在Tuple的第二个元素，就更方便了。直接使用zipWithIndex即可。</p>
<p>zipWithIndex的索引初始值为0，如果想指定索引的初始值，可以使用zip：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l.zip(<span class="type">Stream</span> from <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>13) 应尽量定义小粒度的trait，然后再以混入的方式继承多个trait。例如ScalaTest中的FlatSpec：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlatSpec</span> <span class="keyword">extends</span> <span class="title">FlatSpecLike</span> ...</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">trait</span> <span class="title">FlatSpecLike</span> <span class="keyword">extends</span> <span class="title">Suite</span> <span class="keyword">with</span> <span class="title">ShouldVerb</span> <span class="keyword">with</span> <span class="title">MustVerb</span> <span class="keyword">with</span> <span class="title">CanVerb</span> <span class="keyword">with</span> <span class="title">Informing</span> <span class="title">…</span></span></span><br></pre></td></tr></table></figure></p>
<p>小粒度的trait既有利于重用，同时还有利于对业务逻辑进行单元测试，尤其是当一部分逻辑需要依赖外部环境时，可以运用“关注点分离”的原则，将不依赖于外部环境的逻辑分离到单独的trait中。</p>
<p>14) 优先使用不可变集合。如果确定要使用可变集合，应明确的引用可变集合的命名空间。不要用使用import scala.collection.mutable._；然后引用 Set，应该用下面的方式替代：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collections.mutable</span><br><span class="line"><span class="keyword">val</span> set = mutable.<span class="type">Set</span>()</span><br></pre></td></tr></table></figure></p>
<p>这样更明确在使用一个可变集合。</p>
<p>15) 在自己定义的方法和构造函数里，应适当的接受最宽泛的集合类型。通常可以归结为一个: Iterable, Seq, Set, 或 Map。如果你的方法需要一个 sequence，使用 Seq[T]，而不是List[T]。这样可以分离集合与它的实现，从而达成更好的可扩展性。</p>
<p>16) <strong>应谨慎使用流水线转换的形式。当流水线转换的逻辑比较复杂时，应充分考虑代码的可读性，准确地表达开发者的意图，而不过分追求函数式编程的流水线转换风格。</strong>例如，我们想要从一组投票结果(语言，票数)中统计不同程序语言的票数并按照得票的顺序显示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> votes = <span class="type">Seq</span>((<span class="string">"scala"</span>, <span class="number">1</span>), (<span class="string">"java"</span>, <span class="number">4</span>), (<span class="string">"scala"</span>, <span class="number">10</span>), (<span class="string">"scala"</span>, <span class="number">1</span>), (<span class="string">"python"</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">val</span> orderedVotes = votes</span><br><span class="line">   .groupBy(_._1)</span><br><span class="line">   .map &#123; <span class="keyword">case</span> (which, counts) =&gt;</span><br><span class="line">     (which, counts.foldLeft(<span class="number">0</span>)(_ + _._2))</span><br><span class="line">   &#125;.toSeq</span><br><span class="line">   .sortBy(_._2)</span><br><span class="line">   .reverse</span><br></pre></td></tr></table></figure></p>
<p>上面的代码简洁并且正确，但几乎每个读者都不好理解作者的原本意图。一个策略是声明中间结果和参数：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> votesByLang = votes groupBy &#123; <span class="keyword">case</span> (lang, _) =&gt; lang &#125;</span><br><span class="line"><span class="keyword">val</span> sumByLang = votesByLang map &#123; </span><br><span class="line">     <span class="keyword">case</span> (lang, counts) =&gt;</span><br><span class="line">          <span class="keyword">val</span> countsOnly = counts map &#123; <span class="keyword">case</span> (_, count) =&gt; count &#125;</span><br><span class="line">          (lang, countsOnly.sum)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> orderedVotes = sumByLang.toSeq</span><br><span class="line">   .sortBy &#123; <span class="keyword">case</span> (_, count) =&gt; count &#125;</span><br><span class="line">   .reverse</span><br></pre></td></tr></table></figure></p>
<p>代码也同样简洁，但更清晰的表达了转换的发生(通过命名中间值)，和正在操作的数据的结构(通过命名参数)。</p>
<p>17) 对于Options对象，如果getOrElse能够表达业务逻辑，就应避免对其使用模式匹配。许多集合的操作都提供了返回Options的方法。例如headOption等。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = list.headOption getOrElse <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>这要比模式匹配更清楚：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = list <span class="keyword">match</span> </span><br><span class="line">     <span class="keyword">case</span> head::_ =&gt; head</span><br><span class="line">     <span class="keyword">case</span> <span class="type">Nil</span>: =&gt; <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>18) <strong>当需要对两个或两个以上的集合进行操作时，应优先考虑使用for表达式</strong>，而非map，flatMap等操作。此时，for comprehension会更简洁易读。例如，获取两个字符的所有排列，相同的字符不能出现两次。使用flatMap的代码为：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> chars = 'a' to 'z'</span><br><span class="line"><span class="keyword">val</span> perms = chars flatMap &#123; a =&gt;</span><br><span class="line">  chars flatMap &#123; b =&gt;</span><br><span class="line">    <span class="keyword">if</span> (a != b) <span class="type">Seq</span>(<span class="string">"%c%c"</span>.format(a, b))</span><br><span class="line">    <span class="keyword">else</span> <span class="type">Seq</span>()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>使用for comprehension会更易懂：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">val</span> perms = <span class="keyword">for</span> &#123;</span><br><span class="line">   a &lt;- chars</span><br><span class="line">   b &lt;- chars</span><br><span class="line">   <span class="keyword">if</span> a != b</span><br><span class="line"> &#125; <span class="keyword">yield</span> <span class="string">"%c%c"</span>.format(a, b)</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 高效编码</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>) 应尽量避免让<span class="class"><span class="keyword">trait</span><span class="title">去extend一个class。因为这种做法可能会导致间接的继承多个类，从而产生编译错误。同时，还会导致继承体系的复杂度。</span> </span></span><br><span class="line"><span class="class">```<span class="title">scala</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">StarfleetComponent</span></span></span><br><span class="line"><span class="class"><span class="title">trait</span> <span class="title">StarfleetWarpCore</span> <span class="keyword">extends</span> <span class="title">StarfleetComponent</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">Starship</span> <span class="keyword">extends</span> <span class="title">StarfleetComponent</span> <span class="keyword">with</span> <span class="title">StarfleetWarpCore</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">RomulanStuff</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">won</span>'<span class="title">t</span> <span class="title">compile</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">Warbird</span> <span class="keyword">extends</span> <span class="title">RomulanStuff</span> <span class="keyword">with</span> <span class="title">StarfleetWarpCore</span></span></span><br></pre></td></tr></table></figure></p>
<p>2) <strong>选择使用Seq时，若需要索引下标功能，优先考虑选择Vector，若需要Mutable的集合，则选择ArrayBuffer；<br>若要选择Linear集合，优先选择List，若需要Mutable的集合，则选择ListBuffer</strong>。</p>
<p>3) 如果需要快速、通用、不变、带顺序的集合，应优先考虑使用Vector。Vector很好地平衡了快速的随机选择和快速的随机更新（函数式）操作。Vector是Scala集合库中最灵活的高效集合。一个原则是：当你对选择集合类型犹疑不定时，就应选择使用Vector。</p>
<p>需要注意的是：当我们创建了一个IndexSeq时，Scala实际上会创建Vector对象：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="type">IndexedSeq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">x: <span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>4) 如果需要选择通用的可变集合，应优先考虑使用ArrayBuffer。尤其面对一个大的集合，且新元素总是要添加到集合末尾时，就可以选择ArrayBuffer。如果使用的可变集合特性更近似于List这样的线性集合，则考虑使用ListBuffer。</p>
<p>5) 如果需要将大量数据添加到集合中，建议选择使用List的prepend操作，将这些数据添加到List头部，最后做一次reverse操作。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> l = <span class="type">List</span>[<span class="type">Int</span>]()</span><br><span class="line">(<span class="number">1</span> to max).foreach &#123;</span><br><span class="line">     i =&gt; i +: l</span><br><span class="line">&#125;</span><br><span class="line">l.reverse</span><br></pre></td></tr></table></figure></p>
<p>6) 当一个类的某个字段在获取值时需要耗费资源，并且，该字段的值并非一开始就需要使用。则应将该字段声明为lazy。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> field = computation()</span><br></pre></td></tr></table></figure></p>
<p>7) <strong>在使用Future进行并发处理时，应使用回调的方式，而非阻塞：</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//avoid</span></span><br><span class="line"><span class="keyword">val</span> f = <span class="type">Future</span> &#123;</span><br><span class="line">     <span class="comment">//executing long time</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> result = <span class="type">Await</span>.result(f, <span class="number">5</span> second)</span><br><span class="line"></span><br><span class="line"><span class="comment">//suggesion</span></span><br><span class="line"><span class="keyword">val</span> f = <span class="type">Future</span> &#123;</span><br><span class="line">     <span class="comment">//executing long time</span></span><br><span class="line">&#125;</span><br><span class="line">f.onComplete &#123;</span><br><span class="line">     <span class="keyword">case</span> <span class="type">Success</span>(result) =&gt; <span class="comment">//handle result</span></span><br><span class="line">     <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt; e.printStackTrace</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>8) <strong>若有多个操作需要并行进行同步操作，可以选择使用par集合</strong>。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> urls = <span class="type">List</span>(<span class="string">"http://scala-lang.org"</span>,</span><br><span class="line">  <span class="string">"http://agiledon.github.com"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fromURL</span></span>(url: <span class="type">String</span>) = scala.io.<span class="type">Source</span>.fromURL(url)</span><br><span class="line">  .getLines().mkString(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> t = <span class="type">System</span>.currentTimeMillis()</span><br><span class="line">urls.par.map(fromURL(_))</span><br><span class="line">println(<span class="string">"time: "</span> + (<span class="type">System</span>.currentTimeMillis - t) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure></p>
<p>9) <strong>若有多个操作需要并行进行异步操作，则采用for comprehension对future进行join方式的执行</strong>。例如，假设Cloud.runAlgorithm()方法返回一个Futrue[Int]，可以同时执行多个runAlgorithm方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> result1 = <span class="type">Cloud</span>.runAlgorithm(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> result2 = <span class="type">Cloud</span>.runAlgorithm(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">val</span> result3 = <span class="type">Cloud</span>.runAlgorithm(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> result = <span class="keyword">for</span> &#123;</span><br><span class="line">  r1 &lt;- result1</span><br><span class="line">  r2 &lt;- result2</span><br><span class="line">  r3 &lt;- result3</span><br><span class="line">&#125; <span class="keyword">yield</span> (r1 + r2 + r3)</span><br><span class="line">     </span><br><span class="line">result onSuccess &#123;</span><br><span class="line">  <span class="keyword">case</span> result =&gt; println(<span class="string">s"total = <span class="subst">$result</span>"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>1) 测试类应该与被测试类处于同一包下。如果使用Spec2或ScalaTest的FlatSpec等，则测试类的命名应该为：被测类名 + Spec；若使用JUnit等框架，则测试类的命名为：被测试类名 + Test</p>
<p>2) 测试含有具体实现的trait时，可以让被测试类直接继承Trait。例如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">RecordsGenerator</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">generateRecords</span></span>(table: <span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]]): <span class="type">List</span>[<span class="type">Record</span>] &#123;</span><br><span class="line">          <span class="comment">//...</span></span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RecordsGeneratorSpec</span> <span class="keyword">extends</span> <span class="title">FlatSpec</span> <span class="keyword">with</span> <span class="title">ShouldMatcher</span> <span class="keyword">with</span> <span class="title">RecordGenerator</span> </span>&#123;</span><br><span class="line">     <span class="keyword">val</span> table = <span class="type">List</span>(<span class="type">List</span>(<span class="string">"abc"</span>, <span class="string">"def"</span>), <span class="type">List</span>(<span class="string">"aaa"</span>, <span class="string">"bbb"</span>))</span><br><span class="line">     it should <span class="string">"generate records"</span> in &#123;</span><br><span class="line">          <span class="keyword">val</span> records = generateRecords(table)</span><br><span class="line">          records.size should be(<span class="number">2</span>)</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>3) 若要对文件进行测试，可以用字符串假装文件：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">CsvLine</span> </span>= <span class="type">String</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">formatCsv</span></span>(source: <span class="type">Source</span>): <span class="type">List</span>[<span class="type">CsvLine</span>] = &#123;</span><br><span class="line">     source.getLines(_.replace(<span class="string">", "</span>, <span class="string">"|"</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>formatCsv需要接受一个文件源，例如Source.fromFile(“testdata.txt”)。但在测试时，可以通过Source.fromString方法来生成formatCsv需要接收的Source对象：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">it should <span class="string">"format csv lines"</span> in &#123;</span><br><span class="line">     <span class="keyword">val</span> lines = <span class="type">Source</span>.fromString(<span class="string">"abc, def, hgi\n1, 2, 3\none, two, three"</span>)</span><br><span class="line">     <span class="keyword">val</span> result = formatCsv(lines)</span><br><span class="line">     result.mkString(<span class="string">"\n"</span>) should be(<span class="string">"abc|def|hgi\n1|2|3\none|two|three"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/28/Hadoop的安全机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/28/Hadoop的安全机制/" itemprop="url">Hadoop的安全机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-28T17:31:00+08:00">
                2017-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hadoop Kerberos安全机制介绍</p>
<p>参考: <a href="http://dongxicheng.org/mapreduce/hadoop-kerberos-introduction/" target="_blank" rel="noopener">http://dongxicheng.org/mapreduce/hadoop-kerberos-introduction/</a></p>
<p>在Hadoop1.0.0或者CDH3版本后，加入了Kerberos认证机制。使得集群中的节点就是它们所宣称的，是信赖的。Kerberos可以将认证的密钥在集群部署时事先放到可靠的节点上。集群运行时，集群内的节点使用密钥得到认证。只有被认证过节点才能正常使用。企图冒充的节点由于没有事先得到的密钥信息，无法与集群内部的节点通信。防止了恶意的使用或篡改Hadoop集群的问题，确保了Hadoop集群的可靠安全。</p>
<ul>
<li>解决服务器到服务器的认证<br>由于kerberos对集群里的所有机器都分发了keytab，相互之间使用密钥进行通信，确保不会冒充服务器的情况。集群中的机器就是它们所宣称的，是可靠的。<br>防止了用户伪装成Datanode，Tasktracker，去接受JobTracker，Namenode的任务指派。</li>
<li>解决client到服务器的认证<br>Kerberos对可信任的客户端提供认证，确保他们可以执行作业的相关操作。防止用户恶意冒充client提交作业的情况。<br>用户无法伪装成其他用户入侵到一个HDFS 或者MapReduce集群上<br>用户即使知道datanode的相关信息，也无法读取HDFS上的数据<br>用户无法发送对于作业的操作到JobTracker上</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/28/SparkSQL有必要坐下来聊聊Join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/28/SparkSQL有必要坐下来聊聊Join/" itemprop="url">SparkSQL有必要坐下来聊聊Join</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-28T11:15:46+08:00">
                2017-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自 <a href="http://hbasefly.com/2017/03/19/sparksql-basic-join/" target="_blank" rel="noopener">http://hbasefly.com/2017/03/19/sparksql-basic-join/</a></p>
<p>HashJoin</p>
<p>Broadcast Hash Join</p>
<p>Shuffle Hash Join</p>
<p>Sort-Merge Join</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/19/Java的通用I-O-API设计/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/19/Java的通用I-O-API设计/" itemprop="url">Java的通用I/O API设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-19T20:47:53+08:00">
                2017-03-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/oldratlee/translations/blob/master/generic-io-api-in-java-and-api-design/README.md" target="_blank" rel="noopener">博客</a></p>
<p><a href="https://github.com/oldratlee/io-api/wiki/java-api-design-exercise" target="_blank" rel="noopener">wiki说明</a></p>
<p><a href="https://github.com/oldratlee/io-api" target="_blank" rel="noopener">代码库</a></p>
<p><a href="http://lcsd05.cs.tamu.edu/slides/keynote.pdf" target="_blank" rel="noopener">How to Design a Good API and Why it Matters(by Joshua Bloch)</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/15/作为Scala语法糖的设计模式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/15/作为Scala语法糖的设计模式/" itemprop="url">作为Scala语法糖的设计模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-15T15:49:22+08:00">
                2017-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Scala/" itemprop="url" rel="index">
                    <span itemprop="name">Scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转载: <a href="http://zhangyi.farbox.com/post/designthinking/design-patterns-with-scala-syntax-sugar" target="_blank" rel="noopener">http://zhangyi.farbox.com/post/designthinking/design-patterns-with-scala-syntax-sugar</a></p>
<p>Scala算是一门博采众家之长的语言，兼具OO与FP的特性，若使用恰当，可以更好地将OO与FP的各自优势发挥到极致；然而问题也随之而来，倘若过分地夸大OO特性，Scala就变成了一门精简版的Java，写出的是没有Scala Style的拙劣代码；倘若过分追求FP的不变性等特性，因为Scala在类型系统以及Monad实现的繁琐性，又可能导致代码变得复杂，不易阅读，反而得不偿失。</p>
<p>看来，赋予程序员选择的自由，有时候未必是好事！</p>
<p>在OO世界里，设计模式曾经风靡全世界，你不懂设计模式，都不好意思说自己是程序员。现在呢？说你懂设计模式，倒显得你逼格低了，心里鄙视：“这年头谁还用设计模式，早过时了！”程序员心中的鄙视链开始加成，直接失血二十格。</p>
<p>其实什么事情都得辩证来看！设计模式对OO设计的推进作用不容忽视，更不容轻视。我只是反对那种为了“模式”而“模式”的僵化思想，如果没有明白设计模式的本质思想，了解根本的设计原理，设计模式无非就是花拳绣腿罢了。当然，在FP世界里，设计模式开始变味开始走形，但诸多模式的本质，例如封装、抽象，仍然贯穿其中，不过是表达形式迥然而已罢了。</p>
<p>在混合了OO与FP的Scala语言中，我们来观察设计模式的实现，会非常有趣。Pavel Fatin有篇博客Design Patterns in Scala将Java设计模式与Scala进行了对比，值得一读。我这里想借用他的案例，然后从另一个角度来俯瞰设计模式。</p>
<p>在Pavel Fatin比较的设计模式中，部分模式在Scala中不过是一种语法糖（Syntax Sugar），包括：</p>
<ul>
<li>Factory Method</li>
<li>Lazy Initialization</li>
<li>Singleton</li>
<li>Adapter</li>
<li>Value Object</li>
<li>Factory Method</li>
</ul>
<p>文中给出的Factory Method模式，准确地说其实是静态工厂模式，它并不在GOF 23种模式之列，但作为对复杂创建逻辑的一种封装，常常被开发人员使用。站在OCP（开放封闭原则）的角度讲，该模式对扩展不是开放的，但对于修改而言，却是封闭的。如果创建逻辑发生了变化，可以保证仅修改该静态工厂方法一处。同时，该模式还可以极大地简化对象创建的API。</p>
<p>在Scala中，通过引入伴生对象（Companion Object）来简化静态工厂方法，语法更加干净，体现了Scala精简的设计哲学。即使不是要使用静态工厂，我们也常常建议为Scala类定义伴生对象，尤其是在DSL上下文中，更是如此，因为这样可以减少new关键字对代码的干扰。</p>
<h2 id="Lazy-Initialization"><a href="#Lazy-Initialization" class="headerlink" title="Lazy Initialization"></a>Lazy Initialization</h2><p>lazy修饰符在Scala中有更深远的涵义，例如牵涉到所谓严格（Strictness）函数与非严格（Non-strictness）函数。在Scala中，若未明确声明，所有函数都是严格求值的，即函数会立即对它的参数进行求值。而如果对val变量添加lazy修饰符，则Scala会延迟对该变量求值，直到它第一次被引用时。如果要定义非严格函数，可以将函数设置为by name参数。</p>
<p>scala的lazy修饰符常常被用作定义一些消耗资源的变量。这些资源在初始化时并不需要，只有在调用某些方法时，才需要准备好这些资源。例如在Spark SQL的QeuryExecution类中，包括optimizedPlan、sparkPlan、executedPlan以及toRdd等，都被定义为lazy val：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueryExecution</span>(<span class="params">val sparkSession: <span class="type">SparkSession</span>, val logical: <span class="type">LogicalPlan</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> analyzed: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    sparkSession.sessionState.analyzer.execute(logical)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> withCachedData: <span class="type">LogicalPlan</span> = &#123;</span><br><span class="line">    assertAnalyzed()</span><br><span class="line">    assertSupported()</span><br><span class="line">    sparkSession.sharedState.cacheManager.useCachedData(analyzed)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> optimizedPlan: <span class="type">LogicalPlan</span> = sparkSession.sessionState.optimizer.execute(withCachedData)</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> executedPlan: <span class="type">SparkPlan</span> = prepareForExecution(sparkPlan)</span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executedPlan.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样设计有一个好处是，当程序在执行到这些步骤时，并不会被马上执行，从而使得初始化QueryExecution变得更快。只有在需要时，这些变量对应的代码才会执行。这也是延迟加载的涵义。</p>
<h2 id="Singleton-Pattern"><a href="#Singleton-Pattern" class="headerlink" title="Singleton Pattern"></a>Singleton Pattern</h2><p>C#提供了静态类的概念，但Java没有，而Scala则通过引入Object弥补了Java的这一缺失，而且从语义上讲，似乎比静态类（Static Class）更容易让人理解。</p>
<p>Object可以派生自多个trait。例如派生自App trait，就可直接享有main函数的福利。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">App</span> <span class="keyword">extends</span> <span class="title">DelayedInit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">    <span class="keyword">this</span>._args = args</span><br><span class="line">    <span class="keyword">for</span> (proc &lt;- initCode) proc()</span><br><span class="line">    <span class="keyword">if</span> (util.<span class="type">Properties</span>.propIsSet(<span class="string">"scala.time"</span>)) &#123;</span><br><span class="line">      <span class="keyword">val</span> total = currentTime - executionStart</span><br><span class="line">      <span class="type">Console</span>.println(<span class="string">"[total "</span> + total + <span class="string">"ms]"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Main</span> <span class="keyword">extends</span> <span class="title">App</span></span></span><br></pre></td></tr></table></figure>
<p>继承多个trait的好处是代码复用。我们可以将许多小粒度方法的实现定义在多个trait中。这些方法如果被类继承，则成为实例方法，如果被Object继承，则变成了线程安全的静态方法（因为继承trait的实现就是一个mixin）。多么奇妙！所以很多时候，我们会尽量保证Obejct的短小精悍，然后将许多逻辑放到trait中。当你看到如下代码时，其实不必惊讶：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Main</span> <span class="keyword">extends</span> <span class="title">App</span> </span></span><br><span class="line"><span class="class">  <span class="keyword">with</span> <span class="title">InitHook</span></span></span><br><span class="line"><span class="class">  <span class="keyword">with</span> <span class="title">ShutdownHook</span></span></span><br><span class="line"><span class="class">  <span class="keyword">with</span> <span class="title">ActorSystemProvider</span></span></span><br><span class="line"><span class="class">  <span class="keyword">with</span> <span class="title">ScheduledTaskSupport</span></span></span><br></pre></td></tr></table></figure></p>
<p>这种小粒度的trait既可以保证代码的复用，也有助于职责分离，还有利于测试。真是再好不过了！</p>
<h2 id="Adapter-Pattern"><a href="#Adapter-Pattern" class="headerlink" title="Adapter Pattern"></a>Adapter Pattern</h2><p>隐式转换当然可以用作Adapter。在Scala中，之所以可以更好地调用Java库，隐式转换功不可没。从语法上看，隐式转换比C#提供的扩展方法更强大，适用范围更广。</p>
<p>Pavel Fatin给出了日志转换的Adapter案例：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Log</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">warning</span></span>(message: <span class="type">String</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">error</span></span>(message: <span class="type">String</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Logger</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">log</span></span>(level: <span class="type">Level</span>, message: <span class="type">String</span>) &#123; <span class="comment">/* ... */</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">LoggerToLogAdapter</span>(<span class="params">logger: <span class="type">Logger</span></span>) <span class="keyword">extends</span> <span class="title">Log</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">warning</span></span>(message: <span class="type">String</span>) &#123; logger.log(<span class="type">WARNING</span>, message) &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">error</span></span>(message: <span class="type">String</span>) &#123; logger.log(<span class="type">ERROR</span>, message) &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> log: <span class="type">Log</span> = <span class="keyword">new</span> <span class="type">Logger</span>()</span><br></pre></td></tr></table></figure></p>
<p>这里的隐式类LoggerToLogAdapter可以将Logger适配为Log。与Java实现Adapter模式不同的是，我们不需要去创建LoggerToLogAdapter的实例。如上代码中，创建的是Logger实例。Logger自身与Log无关，但在创建该对象的上下文中，由于我们定义了隐式类，当Scala编译器遇到该隐式类时，就会为Logger添加通过隐式类定义的代码，包括隐式类中定义的对Log的继承，以及额外增加的warning与error方法。</p>
<p>在大多数场景，Adapter关注的是接口之间的适配。但是，当要适配的接口只有一个函数时，在支持高阶函数（甚至只要支持Lambda）的语言中，此时的Adapter模式就味如鸡肋了。假设Log与Logger接口只有一个log函数（不管它的函数名是什么），接收的参数为(Level, String)，那么从抽象的角度来看，它们其实属于相同的一个抽象：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f: (<span class="type">Level</span>, <span class="type">String</span>) =&gt; <span class="type">Unit</span></span><br></pre></td></tr></table></figure></p>
<p>任何一个符合该定义的函数，都是完全适配的，没有类型与函数名的约束。</p>
<p>如果再加上泛型，抽象会更加彻底。例如典型的Load Pattern实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">using</span></span>[<span class="type">A</span>](r : <span class="type">Resource</span>)(f : <span class="type">Resource</span> =&gt; <span class="type">A</span>) : <span class="type">A</span> =</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        f(r)</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        r.dispose()</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>泛型A可以是任何类型，包括Unit类型。这里的f扩大了抽象范围，只要满足从Resource转换到A的语义，都可以传递给using函数。更而甚者可以完全抛开对Resource类型的依赖，只需要定义了close()方法，都可以作为参数传入：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">using</span></span>[<span class="type">A</span> &lt;: <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>():<span class="type">Unit</span>, <span class="type">B</span>][resource: <span class="type">A</span>](f: <span class="type">A</span> =&gt; <span class="type">B</span>): <span class="type">B</span> =</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        f(resource)</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        resource.close()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">using(io.<span class="type">Source</span>.fromFile(<span class="string">"example.txt"</span>)) &#123; source =&gt; &#123;</span><br><span class="line">    <span class="keyword">for</span> (line &lt;- source.getLines) &#123;</span><br><span class="line">        println(line)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为FileResource定义了close()函数，所以可以作为参数传给using()函数。</p>
<h2 id="Value-Object"><a href="#Value-Object" class="headerlink" title="Value Object"></a>Value Object</h2><p>Value Object来自DDD中的概念，通常指的是没有唯一标识的不变对象。Java没有Value Object的语法，然而因其在多数业务领域中被频繁使用，Scala为其提供了快捷语法Case Class。在几乎所有的Scala项目中，都可以看到Case Class的身影。除了在业务中表现Value Object之外，还可以用于消息传递（例如AKKA在Actor之间传递的消息）、序列化等场景。此外，Case Class又可以很好地支持模式匹配，或者作为典型的代数数据类型（ADT）。例如Scala中的List，可以被定义为：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">List</span>[+<span class="type">T</span>]</span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">Nil</span> <span class="keyword">extends</span> <span class="title">List</span>[<span class="type">Nothing</span>]</span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Cons</span>[+<span class="type">T</span>](<span class="params">h: <span class="type">T</span>, t: <span class="type">List</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">List</span>[<span class="type">T</span>]</span></span><br></pre></td></tr></table></figure>
<p>这里，case object是一个单例的值对象。而Nil与Cons又都同时继承自一个sealed trait。在消息定义时，我们常常采用这样的ADT定义。例如List定义中，Nil与Cons就是List ADT的sum或者union，而Cons构造器则被称之为是参数h（代表List的head）与t（代表List的tail）的product。这也是ADT（algebraic data type）之所以得名。注意它与OO中的ADT（抽象数据类型）是风马牛不相及的两个概念。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/15/Spark的UDF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/15/Spark的UDF/" itemprop="url">Spark的UDF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-15T10:52:24+08:00">
                2017-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参考:<br><a href="http://zhangyi.farbox.com/post/framework/udf-and-udaf-in-spark" target="_blank" rel="noopener">http://zhangyi.farbox.com/post/framework/udf-and-udaf-in-spark</a><br><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$</a></p>
<p>UDF的引入极大地丰富了Spark SQL的表现力。一方面，它让我们享受了利用Scala（当然，也包括Java或Python）更为自然地编写代码实现函数的福利，另一方面，又能精简SQL（或者DataFrame的API），更加写意自如地完成复杂的数据分析。尤其采用SQL语句去执行数据分析时，UDF帮助我们在SQL函数与Scala函数之间左右逢源，还可以在一定程度上化解不同数据源具有歧异函数的尴尬。想想不同关系数据库处理日期或时间的函数名称吧！</p>
<h2 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h2><h3 id="注册制"><a href="#注册制" class="headerlink" title="注册制"></a>注册制</h3><p>用Scala编写的UDF与普通的Scala函数没有任何区别，唯一需要多执行的一个步骤是要让SQLContext注册它。例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">len</span></span>(bookTitle: <span class="type">String</span>):<span class="type">Int</span> = bookTitle.length</span><br><span class="line"></span><br><span class="line">sqlContext.udf.register(<span class="string">"len"</span>, len _)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> booksWithLongTitle = sqlContext.sql(<span class="string">"select title, author from books where len(title) &gt; 10"</span>)</span><br></pre></td></tr></table></figure>
<p>编写的UDF可以放到SQL语句的fields部分，也可以作为where、groupBy或者having子句的一部分。</p>
<p>若使用DataFrame的API，则可以以字符串的形式将UDF传入：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> booksWithLongTitle = dataFrame.filter(<span class="string">"longLength(title, 10)"</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="非注册制"><a href="#非注册制" class="headerlink" title="非注册制"></a>非注册制</h3><p>DataFrame的API也可以接收Column对象，可以用$符号来包裹一个字符串表示一个Column。$是定义在SQLContext对象implicits中的一个隐式转换。此时，UDF的定义也不相同，不能直接定义Scala函数，而是要用定义在org.apache.spark.sql.functions中的udf方法来接收一个函数。这种方式无需register：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> longLength = udf((bookTitle: <span class="type">String</span>, length: <span class="type">Int</span>) =&gt; bookTitle.length &gt; length)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sqlContext.implicits._</span><br><span class="line"><span class="keyword">val</span> booksWithLongTitle = dataFrame.filter(longLength($<span class="string">"title"</span>, $<span class="string">"10"</span>))</span><br></pre></td></tr></table></figure></p>
<p>不幸，运行这段代码会抛出异常：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cannot resolve <span class="symbol">'1</span>0' given input columns id, title, author, price, publishedDate;</span><br></pre></td></tr></table></figure>
<p>因为采用$来包裹一个常量，会让Spark错以为这是一个Column。这时，需要定义在org.apache.spark.sql.functions中的lit函数来帮助：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> booksWithLongTitle = dataFrame.filter(longLength($<span class="string">"title"</span>, lit(<span class="number">10</span>)))</span><br></pre></td></tr></table></figure></p>
<h2 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h2><p>参考 <a href="https://databricks.com/blog/2015/09/16/apache-spark-1-5-dataframe-api-highlights.html" target="_blank" rel="noopener">https://databricks.com/blog/2015/09/16/apache-spark-1-5-dataframe-api-highlights.html</a><br>普通的UDF却也存在一个缺陷，就是无法在函数内部支持对表数据的聚合运算。例如，当我要对销量执行年度同比计算，就需要对当年和上一年的销量分别求和，然后再利用同比公式进行计算。此时，UDF就无能为力了。该UDAF（User Defined Aggregate Function）粉墨登场的时候了。</p>
<p>Spark为所有的UDAF定义了一个父类UserDefinedAggregateFunction。要继承这个类，需要实现父类的几个抽象方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span>  输入参数类型，映射为每一个<span class="type">Field</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span>   中间结果类型</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span>   返回结果</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span>  对于一组输入是否输出相同的结果</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span>  初始化buffer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span>  更新row和buffer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span>  merge两个buffer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> 计算最终结果</span><br></pre></td></tr></table></figure></p>
<p>可以将inputSchema理解为UDAF与DataFrame列有关的输入样式。例如年同比函数需要对某个可以运算的指标与时间维度进行处理，就需要在inputSchema中定义它们。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">  <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">"metric"</span>, <span class="type">DoubleType</span>) :: <span class="type">StructField</span>(<span class="string">"timeCategory"</span>, <span class="type">DateType</span>) :: <span class="type">Nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>代码创建了拥有两个StructField的StructType。StructField的名字并没有特别要求，完全可以认为是两个内部结构的列名占位符。至于UDAF具体要操作DataFrame的哪个列，取决于调用者，但前提是数据类型必须符合事先的设置，如这里的DoubleType与DateType类型。这两个类型被定义在org.apache.spark.sql.types中。</p>
<p>bufferSchema用于定义存储聚合运算时产生的中间数据结果的Schema，例如我们需要存储当年与上一年的销量总和，就需要定义两个StructField：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">  <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">"sumOfCurrent"</span>, <span class="type">DoubleType</span>) :: <span class="type">StructField</span>(<span class="string">"sumOfPrevious"</span>, <span class="type">DoubleType</span>) :: <span class="type">Nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>dataType标明了UDAF函数的返回值类型，deterministic是一个布尔值，用以标记针对给定的一组输入，UDAF是否总是生成相同的结果。</p>
<p>顾名思义，initialize就是对聚合运算中间结果的初始化，在我们这个例子中，两个求和的中间值都被初始化为0d：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  buffer.update(<span class="number">0</span>, <span class="number">0.0</span>)</span><br><span class="line">  buffer.update(<span class="number">1</span>, <span class="number">0.0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>update函数的第一个参数为bufferSchema中两个Field的索引，默认以0开始，所以第一行就是针对“sumOfCurrent”的求和值进行初始化。</p>
<p>UDAF的核心计算都发生在update函数中。在我们这个例子中，需要用户设置计算同比的时间周期。这个时间周期值属于外部输入，但却并非inputSchema的一部分，所以应该从UDAF对应类的构造函数中传入。我为时间周期定义了一个样例类，且对于同比函数，我们只要求输入当年的时间周期，上一年的时间周期可以通过对年份减1来完成：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">DateRange</span>(<span class="params">startDate: <span class="type">Timestamp</span>, endDate: <span class="type">Timestamp</span></span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">in</span></span>(targetDate: <span class="type">Date</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    targetDate.before(endDate) &amp;&amp; targetDate.after(startDate)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YearOnYearBasis</span>(<span class="params">current: <span class="type">DateRange</span></span>) <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (current.in(input.getAs[<span class="type">Date</span>](<span class="number">1</span>))) &#123;</span><br><span class="line">      buffer(<span class="number">0</span>) = buffer.getAs[<span class="type">Double</span>](<span class="number">0</span>) + input.getAs[<span class="type">Double</span>](<span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> previous = <span class="type">DateRange</span>(subtractOneYear(current.startDate), subtractOneYear(current.endDate))</span><br><span class="line">    <span class="keyword">if</span> (previous.in(input.getAs[<span class="type">Date</span>](<span class="number">1</span>))) &#123;</span><br><span class="line">      buffer(<span class="number">1</span>) = buffer.getAs[<span class="type">Double</span>](<span class="number">0</span>) + input.getAs[<span class="type">Double</span>](<span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>update函数的第二个参数input: Row对应的并非DataFrame的行，而是被inputSchema投影了的行。以本例而言，每一个input就应该只有两个Field的值。倘若我们在调用这个UDAF函数时，分别传入了销量和销售日期两个列的话，则input(0)代表的就是销量，input(1)代表的就是销售日期。</p>
<p>merge函数负责合并两个聚合运算的buffer，再将其存储到MutableAggregationBuffer中：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  buffer1(<span class="number">0</span>) = buffer1.getAs[<span class="type">Double</span>](<span class="number">0</span>) + buffer2.getAs[<span class="type">Double</span>](<span class="number">0</span>)</span><br><span class="line">  buffer1(<span class="number">1</span>) = buffer1.getAs[<span class="type">Double</span>](<span class="number">1</span>) + buffer2.getAs[<span class="type">Double</span>](<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>最后，由evaluate函数完成对聚合Buffer值的运算，得到最后的结果：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (buffer.getDouble(<span class="number">1</span>) == <span class="number">0.0</span>)</span><br><span class="line">    <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    (buffer.getDouble(<span class="number">0</span>) - buffer.getDouble(<span class="number">1</span>)) / buffer.getDouble(<span class="number">1</span>) * <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>假设我们创建了这样一个简单的DataFrame：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"TestUDF"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sqlContext.implicits._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sales = <span class="type">Seq</span>(</span><br><span class="line">  (<span class="number">1</span>, <span class="string">"Widget Co"</span>, <span class="number">1000.00</span>, <span class="number">0.00</span>, <span class="string">"AZ"</span>, <span class="string">"2014-01-01"</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="string">"Acme Widgets"</span>, <span class="number">2000.00</span>, <span class="number">500.00</span>, <span class="string">"CA"</span>, <span class="string">"2014-02-01"</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="string">"Widgetry"</span>, <span class="number">1000.00</span>, <span class="number">200.00</span>, <span class="string">"CA"</span>, <span class="string">"2015-01-11"</span>),</span><br><span class="line">  (<span class="number">4</span>, <span class="string">"Widgets R Us"</span>, <span class="number">2000.00</span>, <span class="number">0.0</span>, <span class="string">"CA"</span>, <span class="string">"2015-02-19"</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="string">"Ye Olde Widgete"</span>, <span class="number">3000.00</span>, <span class="number">0.0</span>, <span class="string">"MA"</span>, <span class="string">"2015-02-28"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> salesRows = sc.parallelize(sales, <span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> salesDF = salesRows.toDF(<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"sales"</span>, <span class="string">"discount"</span>, <span class="string">"state"</span>, <span class="string">"saleDate"</span>)</span><br><span class="line">salesDF.registerTempTable(<span class="string">"sales"</span>)</span><br></pre></td></tr></table></figure></p>
<p>那么，要使用之前定义的UDAF，则需要实例化该UDAF类，然后再通过udf进行注册：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> current = <span class="type">DateRange</span>(<span class="type">Timestamp</span>.valueOf(<span class="string">"2015-01-01 00:00:00"</span>), <span class="type">Timestamp</span>.valueOf(<span class="string">"2015-12-31 00:00:00"</span>))</span><br><span class="line"><span class="keyword">val</span> yearOnYear = <span class="keyword">new</span> <span class="type">YearOnYearBasis</span>(current)</span><br><span class="line"></span><br><span class="line">sqlContext.udf.register(<span class="string">"yearOnYear"</span>, yearOnYear)</span><br><span class="line"><span class="keyword">val</span> dataFrame = sqlContext.sql(<span class="string">"select yearOnYear(sales, saleDate) as yearOnYear from sales"</span>)</span><br><span class="line">dataFrame.show()</span><br></pre></td></tr></table></figure></p>
<p>在使用上，除了需要对UDAF进行实例化之外，与普通的UDF使用没有任何区别。但显然，UDAF更加地强大和灵活。如果Spark自身没有提供符合你需求的函数，且需要进行较为复杂的聚合运算，UDAF是一个不错的选择。</p>
<p>通过Spark提供的UDF与UDAF，你可以慢慢实现属于自己行业的函数库，让Spark SQL变得越来越强大，对于使用者而言，却能变得越来越简单。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://slamke.github.io/2017/03/02/如何优雅地终止正在运行的Spark-Streaming程序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sun Ke">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雁渡寒潭 风吹疏竹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/02/如何优雅地终止正在运行的Spark-Streaming程序/" itemprop="url">如何优雅地终止正在运行的Spark Streaming程序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-02T14:14:30+08:00">
                2017-03-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自: <a href="https://www.iteblog.com/archives/1890.html" target="_blank" rel="noopener">https://www.iteblog.com/archives/1890.html</a></p>
<p>一直运行的Spark Streaming程序如何关闭呢？是直接使用kill命令强制关闭吗？这种手段是可以达到关闭的目的，但是带来的后果就是可能会导致数据的丢失，因为这时候如果程序正在处理接收到的数据，但是由于接收到kill命令，那它只能停止整个程序，而那些正在处理或者还没有处理的数据可能就会被丢失。那我们咋办？这里有两种方法。</p>
<h2 id="等作业运行完再关闭"><a href="#等作业运行完再关闭" class="headerlink" title="等作业运行完再关闭"></a>等作业运行完再关闭</h2><p>我们都知道，Spark Streaming每隔batchDuration的时间会把源源不断的流数据分割成一批有限数据集，然后计算这些数据，我们可以从Spark提供的监控页面看到当前batch是否执行完成，当作业执行完，我们就可以手动执行kill命令来强制关闭这个Streaming作业。这种方式的缺点就是得盯着监控页面，然后决定关不关闭，很不灵活。</p>
<h2 id="通过Spark内置机制关闭"><a href="#通过Spark内置机制关闭" class="headerlink" title="通过Spark内置机制关闭"></a>通过Spark内置机制关闭</h2><p>其实Spark内置就为我们提供了一种优雅的方法来关闭长期运行的Streaming作业，我们来看看 StreamingContext类中定义的一个 stop 方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stop</span></span>(stopSparkContext: <span class="type">Boolean</span>, stopGracefully: <span class="type">Boolean</span>)</span><br></pre></td></tr></table></figure>
<p>官方文档对其解释是：Stop the execution of the streams, with option of ensuring all received data has been processed. 控制所有接收的数据是否被处理的参数就是 stopGracefully，如果我们将它设置为true，Spark则会等待所有接收的数据被处理完成，然后再关闭计算引擎，这样就可以避免数据的丢失。现在的问题是我们在哪里调用这个stop方法？</p>
<p>Spark 1.4版本之前<br>在Spark 1.4版本之前，我们需要手动调用这个 stop 方法，一种比较合适的方式是通过 Runtime.getRuntime().addShutdownHook 来添加一个钩子，其会在JVM关闭的之前执行传递给他的函数，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="type">Thread</span>() &#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">    log(<span class="string">"Gracefully stop Spark Streaming"</span>)</span><br><span class="line">    streamingContext.stop(<span class="literal">true</span>, <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<p>如果你使用的是Scala，我们还可以通过以下的方法实现类似的功能：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala.sys.addShutdownHook(&#123;</span><br><span class="line">  streamingContext.stop(<span class="literal">true</span>,<span class="literal">true</span>)</span><br><span class="line">)&#125;)</span><br></pre></td></tr></table></figure></p>
<p>通过上面的办法，我们客户确保程序退出之前会执行上面的函数，从而保证Streaming程序关闭的时候不丢失数据。</p>
<p>Spark 1.4版本之后<br>上面方式可以达到我们的需求，但是在每个程序里面都添加这样的重复代码也未免太过麻烦了！值得高兴的是，从Apache Spark 1.4版本开始，Spark内置提供了spark.streaming.stopGracefullyOnShutdown参数来决定是否需要以Gracefully方式来关闭Streaming程序（详情请参见SPARK-7776）。Spark会在启动 StreamingContext 的时候注册这个钩子，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">shutdownHookRef = <span class="type">ShutdownHookManager</span>.addShutdownHook(</span><br><span class="line">          <span class="type">StreamingContext</span>.<span class="type">SHUTDOWN_HOOK_PRIORITY</span>)(stopOnShutdown)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">stopOnShutdown</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> stopGracefully = conf.getBoolean(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="literal">false</span>)</span><br><span class="line">    logInfo(<span class="string">s"Invoking stop(stopGracefully=<span class="subst">$stopGracefully</span>) from shutdown hook"</span>)</span><br><span class="line">    <span class="comment">// Do not stop SparkContext, let its own shutdown hook stop it</span></span><br><span class="line">    stop(stopSparkContext = <span class="literal">false</span>, stopGracefully = stopGracefully)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从上面的代码可以看出，我们可以根据自己的需求来设置 spark.streaming.stopGracefullyOnShutdown 的值，而不需要在每个Streaming程序里面手动调用StreamingContext的stop方法，确实方便多了。不过虽然这个参数在Spark 1.4开始引入，但是却是在Spark 1.6才开始才有文档正式介绍（可以参见<a href="https://github.com/apache/spark/pull/8898和http://spark.apache.org/docs/1.6.0/configuration.html）" target="_blank" rel="noopener">https://github.com/apache/spark/pull/8898和http://spark.apache.org/docs/1.6.0/configuration.html）</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Sun Ke</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">98</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sun Ke</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
